\chapter{Spaaaaaace!}
\section{Introduction}

Now that we're reasonably comfortable with $\R^2$ (don't worry, we'll come back to it) we're gonna take the next step: Consider the set $\R^3$ and study what are its vectors, how they behave etc.

But, as it's going to become apparent very soon, this is essentially \textbf{not different at all} from what we've already been doing for $\R^2$ - some proofs are actually literally the same, without changing anything.

As a consequence, this chapter shall be much shorter than the previous one. Here's the basic schema of this chapter:

\begin{itemize}
	\item First, we're gonna define $\R^3$ and stablish its properties. At this point we'll notice how it's basically $\R^2$ all over again, with some few minor changes;
	\item Then we're gonna prove whatever is new for $\R^3$ and state which results from $\R^2$ still hold.
\end{itemize}

With that said, let us begin!

\newpage
\subsection{A small step for mankind... Kinda}

By definition, $\R^3$ is the set of all ordered triples of real numbers - like $(1,2,3)$ or $(0,\pi, -4)$ etc. We won't go into as much detail as we did for $\R^2$, but we can prove the following result:

\begin{prop}
	The Euclidean space $E_*$ with distinguished point $*$ is in bijection with $\R^3$.
\end{prop}
\begin{cor}
	Every point in $\R^3$ can be thought of as either a point in the space, or a vector from the origin to its endpoint.
\end{cor}

The idea is pretty simple - we can think of any ordered triple $(x,y,z)\in \R^3$ as a set of ``coordinates'' in a grid system which tells us how to move away from the distinguished point $*$: Move $x$ steps away from $*$ in a certain direction, move $y$ steps away from $*$ in a different direction and then $z$ steps away from $*$ in a third direction.

And we can, as before, define:

\begin{df}
	Given two vectors $v=(v_1,v_2,v_3),u=(u_1,u_2,u_3)\in \R^3$ we define their \textbf{sum} $v+u$ to be the unique vector given by
	\[v+u:=(v_1+u_1,v_2+u_2,v_3+u_3).\]
\end{df}

The intuition here is also very similar as it was for $\R^2$: $0,v,u$ define a unique triangle in the space and, by axiom, there's a unique plane containing this triangle. Therefore, $v+u$ is the parallelogram which is contained in that plane and has $0v$ and $0u$ as its sides.

\begin{prop}
	The addition of vectors in $\R^3$ is associative, commutative, has identity element and inverses.
\end{prop}

\begin{df}
	Let us define a few important subsets of $\R^3$:
	\begin{itemize}
		\item The set $\{0\}\times \R\times \R$ will be called the $\mathds{YZ}$-plane;
		\item The set $\R\times\{0\}\times \R$ will be called the $\mathds{XZ}$-plane;
		\item The set $\R\times \R\times \{0\}$ will be called the $\mathds{XY}$-plane;
		\item The set $\R\times\{0\}\times \{0\}$ will be called the $\mathds{X}$-axis;
		\item The set $\{0\}\times \R\times\{0\}$ will be called the $\mathds{Y}$-axis;
		\item The set $\{0\}\times\{0\}\times \R$ will be called the $\mathds{Z}$-axis.
	\end{itemize}
\end{df}

\begin{df}
	Let $v=(v_1,v_2,v_3)\in \R^3$ and $\lambda\in \R$. We define the \textbf{scalar multiplication} of $v$ and $\lambda$ to be the vector $\lambda v\in\R^3$ given by
	\[\lambda v:=(\lambda v_1,\lambda v_2,\lambda v_3).\]
\end{df}

\begin{prop}
	Scalar multiplication of vectors in $\R^3$ is associative, commutative, has identity element and is distributive over both real and vector addition. Not only that, but $\lambda v=0$ if, and only if, $\lambda =0$.
\end{prop}

\begin{df}
	Given any vectors $v,u\in\R^3$ we define:
	\begin{itemize}
		\item $\R v:=\{w\in \R^3\mid w=\lambda v\mbox{ for some }\lambda\in \R\}$ the \textbf{line through zero containing $v$};
		\item $\R v+\R u:=\{w\in \R^3\mid w=\lambda v+\mu u\mbox{ for some }\lambda,\mu\in \R\}$ the \textbf{plane through zero containing $v$ and $u$}. 
	\end{itemize}
\end{df}

\begin{df}
	A subset $X\subseteq\R^3$ is called a \textbf{subspace} if it is closed under addition and scalar multiplication.
\end{df}

\begin{prop}
	Given any two non-zero vectors $v,u\in\R^3$, then both $\R v$ and $\R v+\R u$ are subspaces of $\R^3$.
\end{prop}
\begin{proof}
	Let $v',v''\in \R v$ - that is, $v'=\lambda' v$ and $v''=\lambda'' v$ for some $\lambda',\lambda''\in \R$. Then, for all $\lambda\in \R$:
	\[v'+v''=(\lambda' v)+(\lambda ''v)=(\lambda'+\lambda'')v\in \R v\]
	\[\lambda v'=\lambda(\lambda' v)=(\lambda \lambda')v\in \R v\]so $\R v$ is closed under addition and scalar multiplication.
	
	
	Let $w,w'\in \R v+\R u$ - that is, $w=\lambda v+\mu u$ and $w'=\lambda' v+\mu' u$. Then, for all $\omega \in \R$:
	\[w+w'=(\lambda v+\mu u)+(\lambda' v+\mu' u)=(\lambda+\lambda ')v+(\mu+\mu')u\in \R v+\R u\]
	\[\omega w=\omega(\lambda v+\mu u)=(\omega \lambda)v+(\omega \mu)u\in \R v+\R u\]so $\R v+\R u$ is closed under addition and scalar multiplication.
	
	This ends the proof.
\end{proof}

Now let's give some geometric definitions and interpret them with linear algebra:

\begin{df}
	Two lines are said to be
	\begin{itemize}
		\item \textbf{Parallel} if they lie in the same plane and don't meet;
		\item \textbf{Skew} if they don't lie in the same plane and don't meet;
		\item \textbf{Transversal} if they meet.
	\end{itemize}

Similarly, two planes are said to be \textbf{parallel} if they don't meet, and transversal if they meet.

Finally, a line and a plane are said to be \textbf{parallel} if they don't meet.
\end{df}

\begin{prop}
Any line in $\R^3$ is of the form $\R v+u$ for some vectors $v,u\in \R^3$, and any plane in $\R^3$ is of the form $\R v+\R u+w$ for some vectors $v,u,w\in \R^3$.
\end{prop}
\begin{proof}
	Let $r\subseteq \R^3$ be any line. Then $r\cap \mathds{YZ}$ is either empty, a single point or $r\subseteq \mathds{YZ}$.
	
	\begin{itemize}
		\item If $r\cap\mathds{YZ}$ is a single point $u$, then the line $r'\subseteq\R^3$ which is parallel to $r$ through zero is such that $r=r'+u$.
		
		\item If $r\cap \mathds{YZ}$ is empty or $r\subseteq\mathds{YZ}$, we then check $r\cap \mathds{XY}$ which can be, again, either empty, a single point or $r\subseteq \mathds{XY}$.
		
		\begin{itemize}
			\item If $r\cap \mathds{XY}$ is a single point, just do as we did above, taking a parallel through zero and adding this single point to it.
			
			\item If $r\cap\mathds{XY}$ is empty, then the fact that $r\cap\mathds{YZ}$ is also empty implies that $r\cap\mathds{XZ}$ is a single point and we can just iterate the construction above.
			
			\item If $r\subseteq\mathds{XY}$, then $r=\mathds{XY}\cap\mathds{YZ}=\mathds{Y}$ so it's already a line through zero.
		\end{itemize}
	\end{itemize}

Either way, we can always show that $r$ is parallel to a line through zero.

\bigskip
Let $\pi\subseteq\R^3$ be any plane. Then:
\begin{itemize}
	\item If $\pi\cap\mathds{YZ}$ is a line $s$, then we can take $\pi'$ the plane parallel to $\pi$ through zero, and $v=s\cap \mathds{Y}$ Then clearly $\pi=\pi'+v$.
	
	\item If $\pi\cap\mathds{YZ}=\varnothing$, then surely $\pi\cap \mathds{X}\neq\varnothing$ (since $\mathds{X}\perp\mathds{YZ}$), and since $\pi\parallel\mathds{YZ}$, we can take $v=\mathds{X}\cap r$ and see that $\pi=\mathds{YX}+v$. 
\end{itemize}

Once again, we see that no matter what, $\pi$ is always parallel to a plane through zero.

This ends the proof.
\end{proof}

\newpage
\subsection{Linear functions IN SPACE!}

\begin{df}
	Let $f:\R^3\to \R^3$ be a function. We'll say that $f$ is a \textbf{linear function} if $f(v+u)=f(v)+f(u)$ and $f(\lambda v)=\lambda f(v)$ for all $v,u\in \R^3$ and $\lambda\in \R$.
	
	We'll denote the set of all linear functions in $\R^3$ by $\hom_\R(\R^3,\R^3)$.
\end{df}

\begin{prop}
	Let $f:\R^3\to\R^3$. Then $f$ is linear if, and only if, $$f(x,y,z)=(ax+by+cz,dx+ey+fz,gx+hy+iz)$$ for some $a,b,c,d,e,f,g,h,i\in\R$.
\end{prop}

\begin{lemma}
	Let $f$ be a linear function in $\R^3$. Then $f$ is uniquely determined by how it acts on $(1,0,0)$, $(0,1,0)$ and $(0,0,1)$.
\end{lemma}
\begin{proof}
	Since $f$ is linear, we have that for all $(x,y,z)\in\R^3$ the following equation holds:
	\begin{align*}
	f(x,y,z)&=f((x,0,0)+(0,y,0)+(0,0,z))\\
	&=f(x,0,0)+f(0,y,0)+f(0,0,z)=xf(1,0,0)+yf(0,1,0)+zf(0,0,1)
	\end{align*}So if we put $f(1,0,0)=v$, $f(0,1,0)=u$ and $f(0,0,1)=w$ we see that $f(x,y,z)=xv+yv+zw$.
	
	This ends the proof.
\end{proof}
\begin{cor}
	Let $f:\{(1,0,0),(0,1,0),(0,0,1)\}\to\R^3$. Then there's a unique linear function $f'$ in $\R^3$ such that $f'(x,y,z):=xf(1,0,0)+yf(0,1,0)+zf(0,0,1)$.
\end{cor}

\begin{df}
	We'll denote the vectors $(1,0,0)$, $(0,1,0)$ and $(0,0,1)$ by $e_1,e_2$ and $e_3$, respectively.
\end{df}
\begin{df}
	A finite set $X\subseteq\R^3$ is called a \textbf{base} of $\R^3$ if any linear function is uniquely determined by the image of $X$ - that is, if we write $X=\{x_1,x_2,\cdots,x_n\}$, then for every linear function $f$ in $\R^3$ and for all $v\in \R^3$, there are uniquely determined $\lambda_1,\cdots,\lambda_n\in \R$ such that $f(v)=\lambda_1x_1+\cdots+\lambda_nx_n$.
\end{df}
\begin{df}
	The set $E:=\{e_1,e_2,e_3\}$ is called the \textbf{canonical base} of $\R^3$.
\end{df}

\newpage
\subsection{SubSPACE!!! emissary}

\begin{lemma}
	Let $X,Y\leq \R^3$ be any two subspaces, and take $v\in X\cap Y$ and $t\in X+Y$. Then not only do we have $\R v\subseteq X\cap Y$ and $\R t\subseteq X+Y$, but also $X+\R v=X$ and $Y+\R v=Y$.
\end{lemma}
\begin{proof}
	Let $v\in X\cap Y$ and take $u\in \R v$ - that is, $u=\lambda v$ for some $\lambda\in R$.
	
	Since $v\in X$ and $X$ is a subspace, $\mu v\in X$ for all $\mu\in \R$ - in particular, $u=\lambda v\in X$. Similarly for $Y$, since $v\in Y$ and $Y$ is a subspace, $\mu v\in Y$ for all $\mu\in \R$ and so $u=\lambda v\in Y$.
	
	But this tells us that $u\in X\cap Y$, by definition of set intersection. This shows that any vector of $\R v$ is in $X\cap Y$ - so $\R v\subseteq X\cap Y$.
	
	\bigskip
	Similarly for $t$, since $t\in X+Y$, we can write $t=x+y$ for some $x\in X$ and $y\in Y$. Take then $t'\in \R t$ - that is, $t'=\tau t$ for some $\tau\in \R$.
	
	Now, this implies that $t'=\tau t=\tau(x+y)=\tau x+\tau y$ and since $X$ and $Y$ are subspaces, $\tau x\in X$ and $\tau y\in Y$ - so $\tau x+\tau y\in X+Y$. This shows $\R t\subseteq X+Y$.	
	
	\bigskip
	To show the second statement, it suffices to realize that, by the previous statement, every element of $\R v$ already lies in $X$ and that $X$ is a subspace. So taking $u\in \R v$ and $x\in X$, we see that $x+u\in X$, so $X+\R v\subseteq X$.
	
	Conversely, any element of $X$ is, by definition, in the sum $\R v+X$ - for instance, any $x\in X$ can be seen as $0+x$, because, since $\R v$ is a subspace, $0\in \R v$. This shows that $X\subseteq \R v+X$ and ends the proof (because the argument for $Y$ is exactly the same).
\end{proof}
\begin{cor}
	Let $X,Y\leq \R^3$ be any two subspaces of $\R^3$ such that $Y\subseteq X$. Then $X+Y=X$.
\end{cor}
\begin{proof}
	Clearly, we already have $X\subseteq X+Y$ by definition of addition of subspaces.
	
	Take then any $x+y\in X+Y$. Since $Y\subseteq X$, we have that $y\in X$, and since $X$ is a subspace, we have that $x+y\in X$. So $X+Y\subseteq X$.
	
	This ends the proof.
\end{proof}
\begin{cor}
	Let $X,Y,Z\leq \R^3$ be any three subspaces such that both or either of $Z\subseteq X$ and $Z\subseteq Y$ hold. Then $X+Y+Z=X+Y$.
\end{cor}
\begin{proof}
	Once again, by definition of subspace addition, we already have that $X+Y\subseteq X+Y+Z$.
	
	Take $x+y+z\in X+Y+Z$. Then, since both or either of $Z\subseteq X$ and $Z\subseteq Y$ holds, we see that $z\in X$ or $z\in Y$.
	
	In the first case, we now use the fact that $X$ is a subspace, so $x+z\in X$ and therefore $x+y+z=(x+z)+y\in X+Y$, which shows that $X+Y+Z\subseteq X+Y$.
	
	In the second case, we use the fact that $Y$ is a subspace, so $y+z\in Y$ and therefore $x+y+z=x+(y+z)\in X+Y$, which shows that $X+Y+Z\subseteq X+Y$.
	
	Either way, the result holds and this finishes the proof.
\end{proof}

\begin{lemma}
	Let $X,Y,Z\leq \R^3$. Then $$X+(Y\cap Z)=(X+Y)\cap(X+Z)$$$$X\cap(Y+Z)=(X\cap Y)+(X\cap Z).$$
\end{lemma}
\begin{proof}
	Take $x\in X$ and $w\in Y\cap Z$. Then, by definition, $x+w\in X+(Y\cap Z)$. Since $Y$ is a subspace and $w\in Y$, $x+w\in X+Y$. Similarly, since $Z$ is a subspace and $w\in Z$, $x+w\in X+Z$. Therefore, $x+w\in (X+Y)\cap(X+Z)$, so 
	\[X+(Y\cap Z)\subseteq (X+Y)\cap(X+Z).\]
	
	\bigskip
	Conversely, take $v\in(X+Y)\cap(X+Z)$. However, $X\subseteq X+Y$ and $X\subseteq X+Z$ together imply, by definition of intersection, that $(X+Y)\cap(X+Z)\subseteq X$ - so $v\in X$. Finally, since $X\subseteq X+(Y\cap Z)$, this shows that $v\in X+(Y\cap Z)$, so
	\[X+(Y\cap Z)=(X+Y)\cap(X+Z).\]
	
	\bigskip
	The second statement is analogous:
	
	Clearly $X\cap(Y+Z)$ contains both $X\cap Y$ and $X\cap Z$: If we take $y\in X\cap Y$, it is, in particular, in $Y$ and $X$. But since it is in $Y$, it is also in $Y+Z$. Now we see that this $y$ is in both $X$ and $Y+Z$, so it is in $X\cap(Y+Z)$. We can do the same reasoning to show that any $z\in X\cap Z$ is also in $X\cap (Y+Z)$.
	
	Now, by definition of subspace addition, since $X\cap(Y+Z)$ contains both of $X\cap Y$ and $X\cap Z$, it must be contained in their sum - that is, $(X\cap Y)+(X\cap Z)$.
	
	This shows $X\cap(Y+Z)\subseteq (X\cap Y)+(X\cap Z)$.
	
	\bigskip
	Conversely, any element of $(X\cap Y)+(X\cap Z)$ is of the form $v+u$ where $v\in X\cap Y$ and $u\in X\cap Z$. Notice, however, that both $v$ and $u$ lie, in particular, in $X$ - and since $X$ is a subspace, $v+u\in X$.
	
	On the other hand, since $v\in X\cap Y$ and $u\in X\cap Z$, in particular we have $v\in Y$ and $u\in Z$, so $v+u\in Y+Z$.
	
	Since $v+u\in X$ and $v+u\in Y+Z$ we can conclude that $v+u\in X\cap(Y+Z)$ and so
	\[(X\cap Y)+(X\cap Z)\subseteq X\cap(Y+Z).\]
	
	This shows that $X\cap(Y+Z)=(X\cap Y)+(X\cap Z)$ and ends the proof.
\end{proof}

\begin{prop}
	Let $v,u\in \R^3$ be any two non-null vectors. Then for any non-null $w\in\R v$ we have that $\R v=\R w$ and for any non-null $t\in \R v+\R u$ such that $t\notin \R v$ and $t\notin \R u$ we have that $\R t+\R u=\R v+\R t=\R v+\R u$.
\end{prop}
\begin{proof}
	If $w\in \R v$, then $w=\lambda v$ for some $\lambda\in \R$. Take then any other $w'\in \R v$. Once again, this means that $w'=\lambda' v$ for some $\lambda'\in \R$. But now, clearly we have
	\[w'=\lambda'v=\lambda'\frac{\lambda}{\lambda}v=\frac{\lambda'}{\lambda}\lambda v=\frac{\lambda'}{\lambda}w\]so $w'\in \R w$ and $\R v\subseteq \R w$.
	
	Conversely, every $w'\in \R w$ is of the form $w'=\omega w$ for some $\omega\in \R$, but since $w=\lambda v$, we have that
	\[w'=\omega w=(\omega \lambda) v\]so $w'\in \R v$ and $\R w\subseteq \R v$.
	
	Therefore $\R v=\R w$.
	
	\bigskip
	To prove the second statement, we proceed analogously: Take $t\in \R v+\R u$. This means that $t=\tau_1 v+\tau_2 u$ for some $\tau_1,\tau_2\in \R$. Notice that both of $\tau_1$ and $\tau_2$ must be non-zero, because otherwise $t$ would be on either or both of $\R v$ and $\R u$.
	
	Given any $t'\in \R v+\R u$, once again we can write it as $t'=\tau'_1 v+\tau_2' u$.
	
	Since $\tau_1\neq0$, we can then do
	\begin{align*}
		t'&=\tau'_1 v+\tau_2' u\\
		&=\tau'_1\frac{\tau_1}{\tau_1}v+\tau_2'u\\
		&=\frac{\tau_1'}{\tau_1}\tau_1v+\tau_2'u\\
		&=\frac{\tau_1'}{\tau_1}(t-\tau_2u)+\tau_2'u\\
		&=\frac{\tau_1'}{\tau_1}t-\frac{\tau_1'}{\tau_1}\tau_2u+\tau_2'u=\frac{\tau_1'}{\tau_1}t+\left(\tau_2'-\frac{\tau_1'}{\tau_1}\tau_2\right)u
	\end{align*}and we see that $t'\in \R t+\R u$.
	
	Since $\tau_2\neq 0$, we can then do
	\begin{align*}
	t'&=\tau'_1 v+\tau_2' u\\
	&=\tau'_1v+\tau_2'\frac{\tau_2}{\tau_2}u\\
	&=\tau'_1v+\frac{\tau_2'}{\tau_2}\tau_2u\\
	&=\tau'_1v+\frac{\tau_2'}{\tau_2}(t-\tau_1v)\\
	&=\tau_1'v+\frac{\tau_2'}{\tau_2}t-\frac{\tau_2'}{\tau_2}\tau_1v\\
	&=\left(\tau_1'-\frac{\tau_2'}{\tau_2}\tau_1\right)v+\frac{\tau_2'}{\tau_2}t
	\end{align*}and we see that $t'\in \R v+\R t$.
	
	So clearly, $t'\in \R v+\R u$ implies both of $t'\in \R t+\R u$ and $t'\in \R v+\R t$ - and therefore, $\R v+\R u$ is contained in both $\R v+\R t$ and $\R t+ \R u$.
	
	\bigskip
	On the other hand, take $x\in \R t+\R u$. This means that $x=\tau t+\mu u$ for some $\tau,\mu\in \R$. But then, since $t=\tau_1v+\tau_2u$, this tells us that
	\[x=\tau t+\mu u=\tau(\tau_1v+\tau_2u)+\mu u=(\tau\tau_1)v+(\tau\tau_2+\mu)u\]so $x\in \R v+\R u$ which shows that $\R t+\R u\subseteq \R v+\R u$.
	
	Similarly, for all $y\in \R v+\R t$ we can write it as $y=\lambda v+\tau t$ for some $\lambda,\tau\in \R$, so
	\[y=\lambda v+\tau t=\lambda v+\tau(\tau_1v+\tau_2u)=(\lambda+\tau\tau_1)v+(\tau\tau_2)u\]and we see $y\in \R v+\R u$, which implies $\R v+\R t\subseteq \R v+\R u$.
	
	\bigskip
	Now, finally, we have $$\R v+\R t\subseteq\R v+\R u\subseteq \R t+\R u$$and
	\[\R t+\R u\subseteq\R v+\R u\subseteq\R v+\R t\]so this implies that $\R v+\R t=\R t+\R u$ and therefore both of them equal $\R v+\R u$.
	
	This ends the proof.
\end{proof}

\begin{df}
	Let $v,u\in \R^3$ be two vectors such that $\R v=\R u$. In this case we say that $v$ and $u$ are \textbf{parallel}, which we denote by $v\parallel u$.
\end{df}

\begin{lemma}
	The planes $\mb{XY}$, $\mb{YZ}$ and $\mb{ZX}$ are just the sums $\mb{X+Y}$, $\mb{Y+Z}$ and $\mb{Z+X}$, respectively.
\end{lemma}
\begin{proof}
	We'll show that $\mb{XY=X+Y}$. The other are analogous and will be left as an exercise to the reader.
	
	By definition, $\mb{XY}=\R\times \R\times \{0\}$. This means that $v\in \mb{XY}$ if, and only if, $v=(x,y,0)$ for some $x,y\in \R$.
	
	Clearly, then, for all $v\in \mb{XY}$ we can write it as $v=xe_1+ye_2+0e_3=xe_1+y_2$ which shows that $v\in \mb{X+Y}$ - and so $\mb{XY\subseteq X+Y}$.
	
	\bigskip
	Conversely, given any $u\in \mb{X+Y}$ there exists some $x\in \mb X$ and $y\in \mb Y$ such that $u=x+y$. But since $\mb X=\R e_1$, we see that $x=x'e_1$ and since $\mb Y=\Re_2$ we see that $y=y'e_2$, for some $x',y'\in \R$. This tells us that
	\[u=x+y=x'e_1+y'e_2=x'e_1+y'e_2+0e_3=(x',y',0)\]and so $u\in \mb{XY}$.
	
	This shows us that $\mb{XY}\subseteq \mb{X+Y}$, and ends the proof.
\end{proof}

\begin{cor}
	The following equation holds in $\R^3$:
	\[\mb{X+Y+Z}=\R^3=\mb{XY+YZ+ZX}.\]
\end{cor}
\begin{proof}
	The first equation is trivial: $\mb X=\R e_1$, $\mb Y=\R e_2$ and $\mb Z=\R e_3$, by definition, and we know that $E=\{e_1,e_2,e_3\}$ is a base. This means that any vector $v\in \R^3$ can be written with uniquely determined scalars $v_1,v_2,v_3\in\R$ as
	\[v=v_1e_1+v_2e_2+v_3e_3\]this tells us that $v\in \mb{X+Y+Z}$, and so $\R^3\subseteq \mb{X+Y+Z}$.
	
	Conversely, we have that $\mb{X+Y+Z}\subseteq \R^3$ simply by the fact that every element of $\mb{X+Y+Z}$ is, by definition, a sum of vectors, all of which lie in $\R^3$ - and hence so does their sum.
	
	\bigskip
	We would now like to show that $\R^3=\mb{XY+YZ+ZX}$, but in light of the preceding lemma, $\mb{XY+YZ+XZ}$ is just $\mb{X+Y+Y+Z+Z+X}$ which we already know is simply $\mb{X+Y+Z}$ - and this we've already proven to be equal to $\R^3$.
	
	This ends the proof.
\end{proof}
\begin{cor}
	We can weaken the preceding equation a bit:
	\[\mb{XY+YZ=YZ+ZX=ZX+XY}=\R^3.\]
\end{cor}
\begin{proof}
	It follows by the simple observation that all the subspace additions above equal $\mb{X+Y+Z}$.
\end{proof}
\begin{cor}
	Finally, we can weaken it even further:
	\[\mb{XY+Z=YZ+X=ZX+Y}=\R^3.\]
\end{cor}
\begin{proof}
	The same proof as above, since all of these sums equal $\mb{X+Y+Z}$.
\end{proof}

We can now use this to start classifying all subspaces of $\R^3$:

\begin{prop}
	Let $\pi,\sigma\subseteq\R^3$ be any two distinct planes through zero. Then $\pi+\sigma=\R^3$.
\end{prop}
\begin{proof}
	Let $\pi=\R p_1\R p_2$ and $\sigma=\R s_1+\R s_2$ for some vectors $p_1,p_2,s_1,s_2\in \R^3$. Notice that (at least) one of
	\[p_1\parallel s_1\quad\quad p_1\parallel s_2\]
	\[p_2\parallel s_1\quad\quad p_2\parallel s_2\]must not hold - otherwise, the planes would be equal.
\end{proof}