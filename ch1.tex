\chapter{Basic set theory}
\section{Naive set theory}
\subsection{Axioms and you}

Most, if not all, concepts in mathematics are phrased in the language of set theory: Geometric figures are just collections of points, transformations between two different objects are the collections of all the transitional states inbetween etc.

Hence, it makes sense to give some more formal foothold when studying any area of maths by beginning with some basic set theory.

But then, why \textit{naive}?

Well, formal mathematics (that is, all contemporary and modern mathematics for more than a hundred years) is based on what we like to call \textit{axioms} - you can think of them as the ``rules of the game'', in some sense.

Let me give you all an example of a well-accepted axiom of Euclidean geometry:

\begin{blockenv}{Axiom}
	Given any two distinct points, there is one, and only one, line through them.
\end{blockenv}

Some people say it's ``something that you can't prove", but it's not exactly that - axioms are either things that you don't \textit{want} to prove, and just want to assume as truth (maybe because it is, indeed, impossible to prove it) or things that are, in some vague sense, ``natural" or ``self-evident".

Either way, the correct mindset to approach axioms is to think of them as the building blocks with which you build maths - just like atoms are the building blocks of matter -: by combining different axioms in different ways you get different results - the so called ``theorems''.

That's what maths is all about: Working with axioms and already proven theorems to prove new theorems. It's kinda like a game of scrabble, where the axioms are not only the blocks you (and everyone else) has in their hands, but also the rules of the game and the game board, and the theorems are the words you can make - subject to the rules of the game, the pieces and the board.

Hence, \textit{naive} set theory is called so not because it is a theory of naive sets, but because it's a theory that's not properly formalized, and relies heavily on intuition and common sense.

In proper, axiomatic, set theory you'd have to define what is, and what isn't, a set. In naive set theory, however, we can just hand-wave it and say
\begin{blockenv}{Naive axiom(?)}
	Any collection of things is a set.
\end{blockenv}

Now, as to \textit{why} this isn't formal, it's due to the fact that it leads to a logical contradiction - a paradox. We're gonna show this contradiction in what follows, but if it doesn't interest you (you filthy, you) you can just skip the next section. It's fine, I won't judge you (actually, I will).

\subsection{Russell's Paradox}

Imagine that every random collection of random things is a set. Then it is only natural to consider the collection of all sets. But, since it is a collection (duh) it is also a set. But since it is the collection of all sets, it is an element of itself.

That's weird, ok? Try thinking of any sets - I'll give you plenty of time, don't worry - that are like that: they contain themselves as elements. You can't, right?

While that's not a contradiction, per se, it \textit{really is weird}.

So let us consider $N$ the collection of all non-weird sets - that is, the collection of all sets that do not contain themselves as elements.

Now, one naturally asks the question: Is $N$ itself a weird set? That is, $N\in N$?

Well, I don't know. But if it was, then, by definition, all elements of $N$ are non-weird sets, so $N$, being an element of $N$, would have to be a non-weird set - that is, $N\notin N$. So... If we assume that $N\in N$ we can logically infer that $N\notin N$...

Okay, maybe we made a mistake all along by assuming that $N\in N$! Yeah, that must be the case! Clearly, $N$ can't be a weird set!... But then, since $N$ isn't weird, it must be an element of $N$ (since $N$ contains \textit{all} non-weird sets)... That is, $N\in N$. So if we assume $N\notin N$ we can logically deduce that $N\in N$.

We have just proven that $N\in N$ and $N\notin N$ are \textit{logically equivalent}. But by the \textbf{Principle of Non-Contradiction} (something can't be simultaneously both true and false) those two can't be equivalent!

So, by assuming that there is a set containing all sets we can logically derive a contradiction - that, my friends, is the definition of a paradox.

This is the famous \textbf{Russell's Paradox} and it applies in broader contexts - it basically means that, from a logical POV, self-references are \textit{kinda weird and you shouldn't actually do that}.

For instance, if you put as an axiom that ``anything that can be stated can be proven", then you could ask ``can I prove that there is something that cannot be proven?" and the answer would have to be \textit{yes}, since you said (by axiom) that everything had to be provable. But that's a contradiction - by forcing everything to have a proof you have proven that you cannot prove everything.

This was proposed by philosopher-mathematician Bertrand Russell to show that maths really does need a formal framework to work with - otherwise we might be working in a system where contradictions arise (as we have seen).

There is, however, a solution to this. We have a set of axioms for set theory called the Zermello-Frankel axioms, which are a list of axioms that do not generate that kind of contradiction. It is, however, \textit{impossible} to prove whether it does or doesn't generate \textit{any} paradox (this is due to a bunch of hard maths/philosophy that is waaaaay out of the scope of this text).

Just know that if you ever see ZFC anywhere you can rest safe because you're working with a (relatively) safe set of axioms.

\section{Basic results and properties of sets}
\subsection{Equality always}

As we have previously stated, a \textit{set} is a collection of objects. We will usually denote a set by a capital letter (not always), such as $X$, $A$ or $B$.

Since we cannot (as seen in the previous section) consider ``the set of all sets'', fix any set $X$. Now, $X$ might be any set - numbers, birds, colours, the numerous of ways you can insult someone's mum etc.

When we have an object that is in that set we say that it is an \textbf{element} of that set, and usually denote it by a non-capital letter (once again, not always). In symbols, if we want to say that $a$ is an element of $X$ we would write that as $a\in X$ - which should be read as ``$a$ is an element of $X$", ``$a$ is in $X$'' or even ``$X$ contains $a$ as an element".

\begin{ex}
	Let $E$ be the collection of all even integers. So $2\in E$ and $28\in E$, but $5\notin E$ (``$5$ isn't in $E$'', or ``$5$ isn't an even integer") and \textit{dog} $\notin E$ (because \textit{dog} is \textbf{not} an even integer). Actually, you can see this as a formal proof of the well known fact that all dogs are \textit{odd}.
\end{ex}

You can, however, take all the elements of a set and ask if they satisfy a certain condition.

\begin{ex}
	Following up on the previous example, let $\phi$ denote the proposition ``\textit{can be written in english with only three letters}''. Now we can consider the \textit{subset} of $E$ formed by all elements of $E$ that also satisfy $\phi$ (if $x\in E$ is such an element, we simply write $\phi(x)$ to denote ``$x$ satifies $\phi$''). This is written as follows:
	$$E_\phi:=\{x\in E\mid \phi(x)\}.$$
	
	Let us break this down bit-by-bit:
	\begin{itemize}
		\item The symbol $E_\phi$ is non-standard notation that we're introducing here to mean ``\textit{the set $E$ subject to the condition $\phi$}'';
		
		\item The symbol $:=$ means ``\textit{equals, by definition}". This can be used in two distinct ways: During a logical regression, we can use this symbol to justify one step by saying ``this thing that I'm claiming is true, is actually true by definition''; or we can use it to define new terms - we're basically saying ``the LHS is a new symbol whose meaning I'm defining to be the RHS'' - kinda like attributing a value to a variable.
		
		In this text we're \textbf{always} going to use this symbol with the second meaning - so in the preceding expression the $:=$ means ``I'm defining $E_\phi$ to mean $\{x\in E\mid \phi(x)\}$".
		
		\item The brackets, in mathematics, almost always denote a \textit{set}, and always are presented with the following structure: $\{A\mid B\}$.
		
		The $A$ part is \textit{what kind of elements does this set have}. In the example above, $x\in E$ means that the elements we're working with are even integers.
		
		The $B$ part is \textit{which condition these elements are subject to}. In the example above, $\phi(x)$ means that the elements of this set must satisfy $\phi$.
	\end{itemize}

Now that that's out of the way, what is $E_\phi$? What are \textit{the even integers that can be written in english using only three letters}? There are only three such numbers: \textbf{two}, \textbf{six} and \textbf{ten}. So we write $E_\phi=\{2,6,10\}$.
\end{ex}

\begin{df}
	Two sets $A$ and $B$ are said to be \textbf{equal} if they have the same elements. This means that every element of $A$ is an element of $B$, and every element of $B$ is an element of $A$.
	
	In this case we write $A=B$.
\end{df}

Let us give some examples of equalities.

\begin{ex}
	\begin{itemize}
		\item Let $A$ be the set of all animals that are wooly, fluffy and go \textit{baa}, and let $B$ be the set of all sheep. Clearly $A=B$.
		\item Let $A$ be the set of roots of the polynomial $x^2-x$ and let $B=\{0,1\}$. It is an easy exercise to see that these two sets are the same.
		\item However, $A=\N$ the set of all natural numbers, and $B=\Z^{\geq0}$ the set of non-negative integers, are \textbf{not} equal sets. You can see this in any proper course of number/set theory, but the elements of $\Z$ are always signed: $-2$, $+6$, $+1$ etc. (aside from $0$), whereas the elements of $\N$ are \textbf{not} signed: $1$, $6$ etc. So $1\notin\Z$ and $+1\notin\N$, and therefore $A\not=B$.
	\end{itemize}
\end{ex}

\begin{rmk}
	In mathematics, a \emph{definition} is the term we use to ``assign'' a new value to a certain term. In the definition above, we assigned a meaning to the phrase ``two sets are equal".
	
	Please be aware that this text will be filled with definitions of this kind, so take your time to get accostumed to them.
\end{rmk}

Notice, however, that we can sort of ``relax'' the conditions of the preceding definition. For instance, consider the following case:

\begin{ex}
	Let $A=\N$ the set of all natural numbers and $B=E$ the set of all even natural numbers. Notice that $A\not=B$ - for instance, $3$ is in $A$, but not in $B$ - so they can't be equal.
	
	On the other hand, notice that it is impossible to produce such a counterexample starting from $B$: No matter which element you choose in $B$ it will always be a natural number, of course, and therefore it will also be an element of $A$.
	
	So these two sets, although not-equal, are not \textit{entirely} different.
\end{ex}

\begin{df}
	Let $A$ and $B$ be two sets such that every element of $B$ is also an element of $A$. In this case, we say that \textbf{$A$ contains $B$ as a subset} - or more simply that \textbf{$B$ is a subset of $A$}, which we'll denote in symbols by $B\subseteq A$.
\end{df}

\begin{ex}
	\begin{itemize}
		\item In the preceding example, we see that $B\subseteq A$.
		\item Take any set $A$, and let $B=A$. We then ask the question: Is $B$ a subset of $A$? Well, by definition, $B\subseteq A$ if, and only if, every element of $B$ is also an element of $A$... But this is trivially true - since $B=A$!
		
		This gives us some insight on our first result:
	\end{itemize}
\end{ex}

\begin{prop}
	For any set $A$ we have that $A\subseteq A$.
\end{prop}
\begin{proof}
	We want to show that every element $a\in A$ is also an element of $A$. But that's trivial. The result follows.
\end{proof}

\begin{rmk}
	In mathematics, a \emph{proof} of a proposition/lemma/theorem/corolary is nothing more than a logical reasoning explaining why what we said is true. Proofs are to mathematics as scientific experiments are to sciences. This is what mathematicians do and work with all their lives.
	
	One could argue that maths is the science of reasoning and arguing.
\end{rmk}

Now we have our first non-trivial result:

\begin{prop}
	Let $A$ and $B$ be two sets. Then $A=B$ if, and only if, $A\subseteq B$ and $B\subseteq A$.
\end{prop}
\begin{proof}
	Assume that $A=B$. We want to show that $A\subseteq B$ and $B\subseteq A$, but this is trivial in light of the preceding proposition.
	
	\bigskip
	Assume now that $A\subseteq B$ and $B\subseteq A$. We want to show that $A=B$ - that is, every element of $A$ is an element of $B$, and every element of $B$ is an element of $A$.
	
	Notice, however, that the phrase ``every element of $A$ is an element of $B$" is the definition of the symbol $A\subseteq B$, and the phrase ``every element of $B$ is an element of $A$" is the definition of the symbol $B\subseteq A$ - both of which we are assuming to be true.
	
	Therefore, we have just proven that $A=B$, as stated, which finishes the proof.
\end{proof}

\begin{rmk}
	In mathematics, an \emph{if, and only if,} statement is the equivalent of a logical equivalence. Basically, whenever we say ``\emph{this} holds if, and only if, \emph{that} holds" what that means is that \emph{this} and \emph{that} are equivalent: \emph{this} is true precisely when \emph{that} is true, and \emph{this} is false precisely when \emph{that} is also false.
	
	Without going too much into propositional logic, we usually write ``$a$ if, and only if, $b$" in symbols as $a\iff b$, which is logically equivalent to saying that ``$a$ being true is sufficient for us to prove that $b$ is also true" and ``$b$ being true is sufficient for us to prove that $a$ is also true". In symbols we would write these, respectively, as $a\implies b$ and $b\implies a$ - which should be read as ``$a$ implies $b$" and ``$b$ implies $a$", respectively.
	
	That's what we did in the preceding proposition: If $a$=``$A=B$" and $b$=``$A\subseteq B$ and $B\subseteq A$", we proved that assuming $a$ we can conclude $b$, and that assuming $b$ we can conclude $a$ that is, we proved that $a$ implies $b$ and $b$ implies $a$ - which is logically equivalent to proving that $a$ and $b$ are equivalent.
\end{rmk}

This proposition is the most common tool used by mathematicians to prove that two sets are equal: We simply prove that each one contains the other - therefore, they must be equal.

\begin{ex}
	Let $A=\{0,1\}$ and $B$ be the set of all possible remainders you could get when dividing a natural number by $2$. For instance: $5:2$ is just $2\cdot 2+1$ - that means it has a remainder of $1$; $8:2$ is just $4\cdot 2+0$ - that means it has a remainder of $0$ etc.
	
	So it would seem from these two examples that the only possible remainders are $0$ and $1$ - that is, $A=B$ - but how can we \textit{prove} that?
	
	We'll just use the precedin proposition!
	
	Clearly $A\subseteq B$ - that is, clearly $0$ and $1$ are possible remainders when dividing by $2$, as the two examples we did show.
	
	Now, let us prove that $B\subseteq A$ - that is, that every such remainder is either $0$ or $1$.
	
	Take any natural number $n$ and divide it by $2$, getting something like $q\cdot 2+ r$ where $q$ is the quotient of this division, and $r$ is the remainder.
	
	What would happen if $r\geq 2$? Well, if $r\geq 2$ then $r-2$ is also an integer - let's call it $s$.
	
	This means - just by rearranging terms - that $s+2=r$. And so, we can rewrite $q\cdot 2+r$ as $q\cdot 2+s+2$, group up all the 2s together as $q\cdot 2+2+s$ and factor out the 2 as $(q+1)\cdot 2+s$.
	
	This is weird - this is saying that $q+1$ is also a quotient of $n$ divided by $2$, but quotients are uniquely defined!
	
	When you divide $n:2$ you should always get the same unique answer - which is $q$ - and we've just shown that you can get \textit{two different answers} (because clearly $q\neq q+1$, otherwise you could prove that $0=1$, just by canceling $q$ on both sides).
	
	Ok, so by assuming that $r\geq2$ we have arrived at a contradiction: we have proven that something which we know to be \textit{false} is actually \textit{true}. This must mean that our assumption that $r\geq 2$ has to be \textit{false} - that is, $r<2$ must be \textit{true}.
	
	Notice that this doesn't lead to any new contradictions (see Russell's Paradox, where either case led to a contradiction) so  $r<2$ being true is the only possible case which doesn't lead to a contradiction.
	
	What we've just shown is that if the remainder is anything \textit{aside} from $0$ and $1$ then our maths would be inconsistent, leading to paradoxes. Since we don't want that, we need the only possible remainders to be $0$ and $1$ - that is, we need $B\subseteq A$.
	
	This shows that $A=B$, just as stated.
\end{ex}

Finally, we can use all that we've done so far to construct a very special set - the empty set.

\begin{ex}
	Let $\N$ be the set of natural numbers and let $\phi$ be the proposition ``is not a natural number". For instance, $\phi({\rm car})$ is just ``car is not a natural number", which is true.
	
	Now we can do just as we did before and consider
	\[\N_\phi:=\{n\in\N\mid \phi(n)\}\]that is, the set of all natural numbers which are not natural numbers.
	
	What \textbf{is} this set? Is there any natural number that isn't a natural number? Of course not! So this is a set \textit{which has no elements}.
	
	Take now $\Z$ the set of all integers and let $\psi$ be the proposition ``is not an integer". We can then define, once more,
	\[\Z_\psi:=\{n\in\Z\mid\psi(n)\}\]that is, the set of all integers which aren't integers.
	
	This set is, once again, empty.
	
	This begets the question: $\N_\phi=\Z_\psi$ - that is, are two empty sets always equal?
\end{ex}

\begin{df}
	Given any set $X$ we call the \textbf{empty set defined by $X$} to be the set of all elements of $X$ which aren't elements of $X$, denoted by $\varnothing_X$.
\end{df}

\begin{theorem}
	Given any two sets $A$ and $B$, then $\varnothing_A=\varnothing_B$.
\end{theorem}
\begin{proof}
	If they were different, then there would either be some element of $\varnothing_A$ which is not in $\varnothing_B$, or some element of $\varnothing_B$ which is not in $\varnothing_A$. But both of these are impossible, since both sets are empty.
	
	So they can't be different, and, therefore, $\varnothing_A=\varnothing_B$
\end{proof}
\begin{cor}
	For any set $A$, its empty set $\varnothing_A$ is uniquely determined.
\end{cor}
\begin{cor}
	There a unique empty set.
\end{cor}

\begin{rmk}
	In mathematics, a \emph{corolary} is a result that follows immediately from something that came before it - sometimes even foregoing a proof because of how immediate this conclusion is.
\end{rmk}

\begin{df}
	We're going to define the \textbf{unique empty set} to be the empty set of any set $A$, which will be denoted in symbols by $\varnothing$.
\end{df}

\subsection{United we stand, intersected we... Fall?}
