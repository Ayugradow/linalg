\chapter{Vetores em $\R^2$}

\section{Definições e Propriedades Básicas}

Em matemática, dados dois conjuntos $A$ e $B$, nós denotamos por $A\times B$ o conjunto de todos os pares ordenados de elementos de $A$ e $B$.

\begin{ex}
	Se $A=\{a,b,c,d\}$ e $B=\{1,2,3\}$, então \[A\times B=\{(a,1),(a,2),(a,3),(b,1),(b,2),(b,3),(c,1),(c,2),(c,3),(d,1),(d,2),(d,3)\}.\]
	
	Se $C=\{\ltimes,\rtimes\}$, então
	\[C\times B=\{(\ltimes,1),(\ltimes,2),(\ltimes 3),(\rtimes,1),(\rtimes,2),(\rtimes 3)\}.\]
	
	Se $D=\{$calça, camiseta$\}$ e $E=\{$azul, verde, amarela$\}$, então
	\[D\times E=\{\mbox{calça azul, calça verde, calça amarela, camiseta azul, camiseta verde, camiseta amarela}\}.\]
\end{ex}

Assim, o conjunto de todos os pares ordenados de números reais é o conjunto $\R\times \R$. Como o símbolo $\times$ remete a um produto, nós chamamos esse conjunto de $\R^2$.

Vamos representar os elementos de $\R^2$ como pontos no plano da seguinte maneira: Correspondemos o elemento $(a,b)\in \R^2$ ao ponto $P$ dado pelas coordenadas $a$ e $b$, como abaixo:

	\[\definecolor{uuuuuu}{rgb}{0.26666666666666666,0.26666666666666666,0.26666666666666666}
	\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=0.75cm,y=0.75cm]
	\begin{axis}[
	x=0.75cm,y=0.75cm,
	axis lines=middle,
	xlabel=$\R$,
	ylabel=$\R$,
	xmin=-3.22,
	xmax=8.520000000000005,
	ymin=-2.1400000000000032,
	ymax=5.76,
	yticklabels={},	
	xticklabels={}]
	\clip(-3.22,-2.14) rectangle (8.52,5.76);
	\draw [dash pattern=on 3pt off 3pt] (0.,2.)-- (4.,2.);
	\draw [dash pattern=on 3pt off 3pt] (4.,0.)-- (4.,2.);
	\begin{scriptsize}
	\draw [fill=black] (4.,2.) circle (2.5pt);
	\draw[color=black] (4.14,2.37) node {$P$};
	\draw [color=uuuuuu] (0.,2.)-- ++(-2.0pt,0 pt) -- ++(4.0pt,0 pt) ++(-2.0pt,-2.0pt) -- ++(0 pt,4.0pt);
	\draw[color=uuuuuu] (-0.32,2) node {$b$};
	\draw [color=uuuuuu] (4.,0.)-- ++(-2.0pt,0 pt) -- ++(4.0pt,0 pt) ++(-2.0pt,-2.0pt) -- ++(0 pt,4.0pt);
	\draw[color=uuuuuu] (4.,-0.4) node {$a$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]
	
Claramente essa correspondência é biunívoca - pois dado um ponto no plano, ele é unicamente determinado por duas coordenadas.

Assim estabelecemos um paralelo entre \textbf{pontos no plano} e \textbf{elementos de $\R^2$}. Por esse motivo, elementos de $\R^2$ são muitas vezes chamados de \textit{pontos} de $\R^2$.

Além disso, podemos fazer outra correspondência:
\[\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
\begin{axis}[
x=1.0cm,y=1.0cm,
axis lines=middle,
xmin=-1,
xmax=6,
ymin=-1,
ymax=4,
xticklabels={},yticklabels={},xlabel=$\R$,ylabel=$\R$,]
\clip(-1.,-1.) rectangle (6.,4.02);
\draw [->] (0.,0.) -- (4.,2.);
\begin{scriptsize}
\draw [fill=black] (4.,2.) circle (2.5pt);
\draw[color=black] (4.14,2.37) node {$P$};
\draw[color=black] (1.88,1.29) node {$v$};
\end{scriptsize}
\end{axis}
\end{tikzpicture}\]

Vamos chamar de \textbf{vetor em $\R^2$} uma seta partindo da origem e terminando em qualquer ponto do plano. A figura acima estabelece uma correspondência biunívoca entre vetores no plano e pontos no plano: Para cada vetor $v$ existe um único ponto final $P$. Similarmente, para cada ponto $P$ existe um único vetor $v$ que termina em $P$.

Juntando tudo isso, nós vemos que \textbf{o conjunto de pontos, pares ordenados e vetores em $\R^2$ são ``a mesma coisa''}. Com isso em mente, daqui para frente vamos usar todos esses significados, usando sempre o significado mais conveniente naquele momento.

\begin{ex}
	\definecolor{ududff}{rgb}{0.30196078431372547,0.30196078431372547,1.}
	\definecolor{xdxdff}{rgb}{0.49019607843137253,0.49019607843137253,1.}
	\[\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\begin{axis}[
	x=1.0cm,y=1.0cm,
	axis lines=middle,
	xmin=-1,
	xmax=3,
	ymin=-1,
	ymax=5,
	xtick={1,2},
	ytick={1,2,3,4},
	xticklabels={},
	yticklabels={},
	xlabel=$\R$,
	ylabel=$\R$]
	\clip(-2.02,-2.02) rectangle (3.98,6.04);
	\draw [->] (0.,0.) -- (2.,4.);
	\draw [dash pattern=on 3pt off 3pt] (2.,4.)-- (2.,0.);
	\draw [dash pattern=on 3pt off 3pt] (2.,4.)-- (0.,4.);
	\begin{scriptsize}
	\draw [fill=black] (2.,4.) circle (2.5pt);
	\draw[color=black] (2.14,4.37) node {$P$};
	\draw[color=black] (0.84,2.25) node {$v$};
	\draw  (2.,0.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw (2,-0.3) node {$2$};
	\draw  (0.,4.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw (-0.3,4) node {$4$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]
	
	A figura acima em $\R^2$ representa simultaneamente os três conceitos: O vetor $v$ tem como ponto final o ponto $P$ cujas coordenadas são $(2,4)$.
\end{ex}

\subsection{Somas e produtos por números}

Dados dois pares ordenados $(a,b)$ e $(c,d)$ em $\R^2$, nós podemos notar que como $a,b,c,d$ são números reais, nós podemos somar $a+c$ e $b+d$, e ambos serão números reais. Assim, faria sentido definir uma operação de soma em $\R^2$ dada por
\[(a,b)+(c,d):=(a+c,b+d).\] Contudo, pelo que já vimos acima, pares, pontos e vetores são ``a mesma coisa''. Será que essa soma tem alguma interpretação via pontos e vetores?

\begin{ex}
	\[\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\begin{axis}[
	x=1.0cm,y=1.0cm,
	axis lines=middle,
	xmin=-1,
	xmax=9,
	ymin=-1,
	ymax=6,
	xticklabels={},
	yticklabels={},
	xtick={0,...,8.0},
	ytick={0,...,5.0},]
	\clip(-2.98,-2.02) rectangle (9.04,6.98);
	\draw [->,] (0.,0.) -- (2.,4.) node[sloped,pos=0.5,above] {$v$};
	\draw [,dash pattern=on 4pt off 4pt] (2.,4.)-- (2.,0.);
	\draw [,dash pattern=on 4pt off 4pt] (2.,4.)-- (0.,4.);
	\draw [->,] (0.,0.) -- (6.,1.) node[sloped,pos=0.5,below] {$u$};
	\draw [,dash pattern=on 4pt off 4pt] (6.,1.)-- (6.,0.);
	\draw [,dash pattern=on 4pt off 4pt] (6.,1.)-- (0.,1.);
	\begin{scriptsize}
	\draw [fill=black] (2.,4.) circle (2.5pt);
	\draw[color=black] (2.14,4.37) node {$P$};
	\draw [color=black] (2.,0.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (2,-0.3) node {$2$};
	\draw [color=black] (0.,4.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (-0.3,4) node {$4$};
	\draw [fill=black] (6.,1.) circle (2.5pt);
	\draw[color=black] (6.14,1.37) node {$Q$};
	\draw [color=black] (6.,0.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (6,-0.37) node {$6$};
	\draw [color=black] (0.,1.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (-0.3,1) node {$1$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]Na figura acima temos os pares $(2,4)$ e $(6,1)$ representados pelos pontos $P$ e $Q$ e pelos vetores $v$ e $u$, respectivamente.
	
	\[\definecolor{qqqqff}{rgb}{0.,0.,1.}
	\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\begin{axis}[
	x=1.0cm,y=1.0cm,
	axis lines=middle,
	xmin=-1,
	xmax=9,
	ymin=-1,
	ymax=6,
	xticklabels={},
	yticklabels={},
	xtick={0,...,8},
	ytick={0,...,5},]
	\clip(-1.,-1.08) rectangle (9.02,6.);
	\draw [->] (0.,0.) -- (2.,4.) node[sloped,pos=0.5,above] {$v$};
	\draw [,dash pattern=on 3pt off 3pt] (2.,4.)-- (2.,0.);
	\draw [,dash pattern=on 3pt off 3pt] (2.,4.)-- (0.,4.);
	\draw [->] (0.,0.) -- (6.,1.) node[sloped,pos=0.5,below] {$u$};
	\draw [,dash pattern=on 3pt off 3pt] (6.,1.)-- (6.,0.);
	\draw [,dash pattern=on 3pt off 3pt] (6.,1.)-- (0.,1.);
	\draw [->,dotted] (6.,1.) -- (8.,5.) node[sloped,pos=0.5,below] {$v$};
	\draw [->,dotted] (2.,4.) -- (8.,5.) node[sloped,pos=0.5,above] {$u$};
	\draw [->,dash pattern=on 1pt off 1pt on 3pt off 4pt] (0.,0.) -- (8.,5.) node[sloped,pos = 0.5,above] {$v+u$};
	\draw [,dash pattern=on 3pt off 3pt] (8.,5.)-- (8.,0.);
	\draw [,dash pattern=on 3pt off 3pt] (8.,5.)-- (0.,5.);
	\begin{scriptsize}
	\draw [fill=black] (2.,4.) circle (2.5pt);
	\draw[color=black] (2.14,4.37) node {$P$};
	\draw [color=black] (2.,0.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (2,-0.3) node {$2$};
	\draw [color=black] (0.,4.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (-0.3,4) node {$4$};
	\draw [fill=black] (6.,1.) circle (2.5pt);
	\draw[color=black] (6.3,1) node {$Q$};
	\draw [color=black] (6.,0.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (6,-0.37) node {$6$};
	\draw [color=black] (0.,1.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (-0.3,1) node {$1$};
	\draw [fill=qqqqff] (8.,5.) circle (2.5pt);
	\draw[color=qqqqff] (8.14,5.37) node {$P+Q$};
	\draw [color=black] (8.,0.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (8,-0.37) node {$8$};
	\draw [color=black] (0.,5.)-- ++(-2.5pt,0 pt) -- ++(5.0pt,0 pt) ++(-2.5pt,-2.5pt) -- ++(0 pt,5.0pt);
	\draw[color=black] (-0.3,5) node {$5$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]Então, somando os pares $(2,4)$ e $(6,1)$ obtemos o par $(2+6,4+1)=(8,5)$. Geometricamente, temos a figura acima: Dados os vetores $v$ e $u$, com coordenadas $(2,4)$ e $(6,1)$, respectivamente, o vetor $v+u$ que é obtido simplesmente pela concatenação do vetor $u$ ao vetor $v$.
\end{ex}

\begin{df}
	Dados dois vetores $u,v\in \R^2$ com coordenadas $u=(a,b)$ e $v=(c,d)$, definimos a \textbf{soma de $u$ com $v$} como sendo o vetor $u+v$ dado por
	\[u+v:=(a+c,b+d).\]
\end{df}

\begin{exerc}
	Mostre que essa soma satisfaz as seguintes propriedades:
	\begin{itemize}
		\item (Comutatividade) Para quaisquer vetores $u,v\in R^2$, $u+v=v+u$;
		\item (Associatividade) Para quaisquer três vetores $u,v,w\in \R^2$, $u+(v+w)=(u+v)+w$;
		\item (Existência e unicidade de elemento neutro) Existe um (único) vetor $\overrightarrow{0}\in \R^2$ tal que $v+\overrightarrow{0}=v$ para qualquer $v\in \R^2$;
		\item (Existência e unicidade de inversos) Para qualquer vetor $v\in\R^2$ existe um (único) vetor $-v\in\R^2$ tal que $v+(-v)=\overrightarrow{0}$.
	\end{itemize}
\end{exerc}

Por outro lado, é intuitivamente óbvio que se $(a,b)\in\R^2$ e $\lambda\in \R$, certamente o par $(\lambda a,\lambda b)\in \R^2$. Então parece natural definir
\[\lambda(a,b):=(\lambda a,\lambda b).\] Contudo, será que temos uma boa interpretação geométrica pra isso, como para a soma?

\begin{ex}
	Fixe o número $\lambda=\dfrac{1}{2}\in\R$ e o vetor $v=(4,2)\in\R^2$.
	\definecolor{ududff}{rgb}{0.30196078431372547,0.30196078431372547,1.}
	\definecolor{xdxdff}{rgb}{0.49019607843137253,0.49019607843137253,1.}
	\[\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\begin{axis}[
	x=1.0cm,y=1.0cm,
	axis lines=middle,
	xmin=-1,
	xmax=5,
	ymin=-1,
	ymax=3,
	xtick={1,...,4},
	ytick={1,2},]
	\clip(-1,-1) rectangle (6,4);
	\draw [->] (0.,0.) -- (4,2) node[sloped,pos=0.5,above] {$v$};
	\draw [dash pattern=on 3pt off 3pt] (4,2)-- (0,2);
	\draw [dash pattern=on 3pt off 3pt] (4,2)-- (4,0);	
	\begin{scriptsize}
	\draw [fill=black] (4,2) circle (2.5pt);
	\draw[color=black] (4,2.37) node {$P$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]O que seria o vetor $u=(2,1)=\left(\dfrac{1}{2}\cdot 4,\dfrac{1}{2}\cdot2\right)=\dfrac{1}{2}\cdot v$?
	
	\[\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\begin{axis}[
	x=1.0cm,y=1.0cm,
	axis lines=middle,
	xmin=-1,
	xmax=5,
	ymin=-1,
	ymax=3,
	xtick={1,...,4},
	ytick={1,2},]
	\clip(-1,-1) rectangle (6,4);
	\draw [->] (0.,0.) -- (4,2) node[sloped,pos=0.7,above] {$v$};
	\draw [->,blue] (0.,0.) -- (2,1) node[sloped,pos=0.7,below] {$\frac{1}{2}v$};
	\draw [dash pattern=on 3pt off 3pt] (4,2)-- (0,2);
	\draw [dash pattern=on 3pt off 3pt] (4,2)-- (4,0);
	\draw [dash pattern=on 3pt off 3pt] (2,1)-- (0,1);
	\draw [dash pattern=on 3pt off 3pt] (2,1)-- (2,0);	
	\begin{scriptsize}
	\draw [fill=black] (4,2) circle (2.5pt);
	\draw[color=black] (4,2.37) node {$P$};
	\draw [fill=blue] (2,1) circle (2.5pt);
	\draw[color=black] (2,1.3) node[blue] {$\frac{1}{2}P$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]
	
	Então o vetor $\dfrac{1}{2}\cdot v$ é o vetor \textbf{na mesma direção de $v$}, mas \textbf{com tamanho igual a $\dfrac{1}{2}$ vezes o tamanho de $v$}.
\end{ex}

\begin{exerc}	
	O que seria, então multiplicar por um número negativo, por exemplo $\lambda=-1\in\R$? Faça um desenho do que seria uma interpretação geométrica para $(-1)\cdot(4,2)$.
\end{exerc}

\begin{exerc}
	Mostre que a multiplicação de vetores por números satisfaz:
	\begin{itemize}
		\item (Comutatividade) $(\lambda\mu)v=(\mu\lambda)v$ para quaisquer números $\lambda,\mu\in \R$ e vetor $v\in \R^2$;
		\item (Associatividade) $\lambda(\mu v)=(\lambda\mu)v$ e para quaisquer números $\lambda,\mu\in \R$ e vetor $v\in \R^2$;
		\item (Existência e unicidade de elemento neutro) Existe um (único) numero real $u\in \R$ tal que $u v=v$ para qualquer vetor $v\in\R^2$;
		\item (Distributividades) Para quaisquer $\lambda,\mu \in \R$ e $v,u\in\R^2$, temos que $\lambda(v+u)=\lambda v=\lambda u$ e $(\lambda+\mu)v=\lambda v+\mu v$.
	\end{itemize}
\end{exerc}

\section{Vetores e Matrizes}

Antes de estudar mais a fundo os vetores, contudo, precisamos estabelecer um paralelo entre o estudo de matrizes e o estudo de vetores:

Considere a função $[-]:\R^2\to M_{2\times 1}(\R)$ dada por
\[[(x,y)]:=\begin{pmatrix}
x\\y
\end{pmatrix}\in M_{2\times 1}(\R).\] Essa função ``não faz nada'': Ela só nos permite enxergar vetores como matrizes coluna. Similarmente, podemos considerar a função $V:M_{2\times 1}(\R)\to \R^2$ dada por 
\[V\begin{pmatrix}
x\\y
\end{pmatrix}:=(x,y)\in \R^2.\] Essa função também ``não faz nada'': Ela só nos permite enxergar matrizes coluna como vetores. Contudo, note que:

\[V([(x,y)])=V\begin{pmatrix}
x\\y
\end{pmatrix}=(x,y)\]
\[\left[V\begin{pmatrix}
x'\\y'
\end{pmatrix}\right]=[(x',y')]=\begin{pmatrix}
x'\\y'
\end{pmatrix}\]ou seja, \textit{essas funções são inversas}! Isso nos diz que os conjuntos $\R^2$ e $M_{2\times 1}(\R)$ são ``a mesma coisa'', apenas vistos com outros olhos. Por isso, vamos adicionar mais um significado à palavra vetor: Não só pontos no plano, ou pares ordenados em $\R^2$ ou setas partindo da origem, mas também matrizes coluna com duas entradas.

\subsection{Funções lineares}

Nesta seção, então, vamos interpretar vários dos resultados do capítulo anterior, mas agora com o auxílio dos diversos significados de vetor.

Por exemplo, dada uma matriz quadrada $A=\begin{pmatrix}
a&b\\c&d
\end{pmatrix}$, a multiplicação $AX$, em que $X$ é alguma matriz coluna com duas entradas, é da seguinte forma:
\[\begin{pmatrix}
a&b\\c&d
\end{pmatrix}\begin{pmatrix}
x\\y
\end{pmatrix}=\begin{pmatrix}
ax+by\\cx+dy
\end{pmatrix}.\] Então para cada valor de $x$ e $y$, o resultado do produto $AX$ é diferente -  ora, isso nos permite definir:

\begin{df}
	Para cada matriz $A\in M_2(\R)$, definimos $T_A:\R^2\to \R^2$ a função dada por
	\[T_A(x,y):=V(A[(x,y)]).\]
\end{df}

\begin{ex}
	Dada a matriz $A=\begin{pmatrix}
	2 & 5\\
	1 & 3
	\end{pmatrix}$, o função $T_A$ é tal que
	\[T_A(x,y)=V(A[(x,y)])=V\left(\begin{pmatrix}
	2 & 5\\
	1 & 3
	\end{pmatrix}\begin{pmatrix}
	x\\y
	\end{pmatrix}\right)=V\left(\begin{pmatrix}
	2x+5y\\x+3y
	\end{pmatrix}\right)=(2x+5y,x+3y)\].
	
	Similarmente,
	\[T_{I_2}(x,y)=V(I_2[(x,y)])=V\left(\begin{pmatrix}
	1&0\\0&1
	\end{pmatrix}\begin{pmatrix}
	x\\y
	\end{pmatrix}\right)=V\left(\begin{pmatrix}
	x\\y
	\end{pmatrix}\right)=(x,y),\] ou seja, a função $T_{I_2}$ é a função identidade que leva todo vetor nele mesmo.
\end{ex}

Como essas funções são dadas por matrizes, será que elas têm as propriedades de matrizes?

\begin{prop}
	Dados uma matriz $A\in M_2(\R)$, qualquer número $\lambda \in \R$ e dois vetores $v,u\in \R^2$, temos:
	\[T_A(\lambda v)=\lambda T_A(v)\]
	\[T_A(v+u)=T_A(v)+T_A(u).\]
\end{prop}

\begin{exerc}
	Prova a proposição acima (dica: calcule explicitamente $T_A(\lambda v)$ e $\lambda T_A(v)$ e veja que são a mesma coisa. Idem para as somas.).
\end{exerc}

Essas funções são bastante interessantes. Elas nos dão um ``dicionário'' que nos permite ver o mundo dos vetores como se fosse o mundo das matrizes, e vice-e-versa. Seria, então, interessante se a gente conseguisse um método de determinar quando uma função $f:\R^2\to \R^2$ é dessa forma. 

\begin{ex}
	A função $f:\R^2\to \R^2$ dada por $f(x,y)=(x,x^2)$ \textbf{não} é dada por uma matriz. Podemos ver isso usando a proposição acima: Se $f$ fosse igual a $T_A$ para alguma matriz $A\in M_2(\R)$, $f(v+u)$ seria igual a $f(v)+f(u)$. Mas
	\[f(0,0)=(0,0^2)=(0,0),\]enquanto
	\[f(1,0)+f(-1,0)=(1,1^2)+(-1,1^2)=(0,2).\] Agora, note que $(0,0)=(1,0)+(-1,0)$. Então nós acabamos de mostrar que $f((1,0)+(-1,0))\neq f(1,0)+f(-1,0)$, ou seja, $f$ \textbf{não pode ser dada por $T_A$}.
\end{ex}

\begin{prop}
	Uma função $f:\R^2 \to \R^2$ é dada por uma matriz se, e somente se, existem números reais $a,b,c,d\in \R$ tais que $f(x,y)=(ax+by,cx+dy)$.
\end{prop}
\begin{proof}
	Suponha que $f$ é dada por uma matriz, ou seja, $f=T_A$ para alguma matriz $A=\begin{pmatrix}
	a&b\\c&d
	\end{pmatrix}\in M_2(\R)$. Então, para qualquer vetor $(x,y)\in \R^2$ temos:
	\[f(x,y)=T_A(x,y)=V(A([x,y]))=V\left(\begin{pmatrix}
	a&b\\c&d
	\end{pmatrix}\begin{pmatrix}
	x\\y
	\end{pmatrix}\right)=V\left(\begin{pmatrix}
	ax+by\\cx+dy
	\end{pmatrix}\right)=(ax+by,cx+dy),\] como queríamos mostrar.
	
	\bigskip
	Por outro lado, suponha que $f(x,y)=(ax+by,cx+dy)$. Afirmamos que a matriz $A=\begin{pmatrix}
	a&b\\c&d
	\end{pmatrix}$ é tal que $f=T_A$. De fato, 
	\[T_A(x,y)=(ax+by,cx+dy)=f(x,y),\]o que encerra a prova.
\end{proof}

Finalmente, agora vamos resolver um problema que será central nesse curso: Será que toda função $f:\R^2\to \R^2$ que preserva somas e produtos por números é dada por matrizes?

\begin{theorem}
	Seja $f:\R^2\to\R^2$ uma função. Então $f(v+\lambda u)=f(v)+\lambda f(u)$ para todo $\lambda\in \R$ e todos $v,u\in \R^2$ se, e somente se, $f=T_A$ para alguma matriz $A\in M_2(\R)$.
\end{theorem}
\begin{proof}
	Já mostramos que se $f=T_A$, então $f(v+\lambda u)=f(v)+\lambda f(u)$.
	
	Suponha, então, que $f(v+\lambda u)=f(v)+\lambda f(u)$. Vamos mostrar que $f=T_A$ para alguma matriz $A$.
	
	Calculando $f(x,y)$ temos:
	\[\begin{array}{rll}
		f(x,y)&=f(x,0)+f(0,y)&\mbox{(já que $f$ preserva somas)}\\
		&=xf(1,0)+yf(0,1)&\mbox{(já que $f$ preserva multipli-}\\
		&&\mbox{cação por números)}.
	\end{array}\]Sejam então $f(1,0)=(a,b)$ e $f(0,1)=(c,d)$. Assim,
	\[\begin{array}{rl}
	f(x,y)&=xf(1,0)+yf(0,1)\\
	&=x(a,b)+y(c,d)\\
	&=(xa,ab)+(yc,yd)=(xa+yc,xb+yd)
	\end{array}\]e, pela proposição anterior, sabemos que $f=T_A$, onde $A=\begin{pmatrix}
	a&c\\b&d
	\end{pmatrix}$, como queríamos mostrar.
\end{proof}

\begin{df}
	Uma função $f:\R^2\to \R^2$ será dita \textbf{linear} se $f(v+\lambda u)=f(v)+\lambda f(u)$ para quaisquer $\lambda\in \R$ e $v,u\in\R^2$.
\end{df}

Então o teorema acima nos diz que as funções lineares são exatamente as funções ``multiplique o seu vetor por uma matriz''.

\begin{ex}
	Sejam $f,g:\R^2\to R^2$ funções lineares. Será que $g\circ f$ e $f\circ g$ também são lineares?
	
	Por exemplo, se $f=T_A$ e $g=T_B$, com
	\[A=\begin{pmatrix}
	1&3\\
	2&5
	\end{pmatrix}\mbox{ e } B=\begin{pmatrix}
	2&5\\
	1&3
	\end{pmatrix},\] temos:
	\begin{align*}
		f(g(x,y))&=f(2x+5y,x+3y)\\
		&=((2x+5y)+3(x+3y),2(2x+5y)+5(x+3y))\\
		&=(2x+5y+3x+9y,4x+10y+5x+15y)=(5x+14y,9x+25y)
	\end{align*}e
	\begin{align*}
		g(f(x,y))&=g(x+3y,2x+5y)\\
		&=(2(x+3y)+5(2x+5y),(x+3y)+3(2x+5y))\\
		&=(2x+6y+10x+25y,x+3y+6x+15y)=(12x+31y,7x+18y),
	\end{align*}ou seja, tanto $f\circ g$ quanto $g\circ f$ são lineares também.
	
	Mas quem são as matrizes $C$ e $D$ tais que $f\circ g=T_C$ e $g\circ f=T_D$? Ou seja, será que conseguimos obter $C$ e $D$ sabendo $A$ e $B$?
	
	No exemplo acima, 
	\[C=\begin{pmatrix}
	5&14\\9&25
	\end{pmatrix}\mbox{ e }D=\begin{pmatrix}
	12&31\\7&18
	\end{pmatrix}.\]
	
	Como $f$ é dada por $A$ e $g$ é dada por $B$, uma boa hipótese é que $C=AB$. De fato:
	\[AB=\begin{pmatrix}
	1&3\\
	2&5
	\end{pmatrix}\begin{pmatrix}
	2&5\\
	1&3
	\end{pmatrix}=\begin{pmatrix}
	2+3&5+9\\4+5&10+15
	\end{pmatrix}=\begin{pmatrix}
	5&10\\14&25
	\end{pmatrix}=C.\] Similarmente, podemos mostrar que $D=BA$.
	
	
	Em suma, isso nos diz o seguinte: A definição de multiplicação de matrizes é feita de forma que a composição de função lineares seja a função dada pelo produto das matrizes correspondentes.
	
	Ou, em outras palavras, poderíamos definir $AB$ como sendo a matriz tal que $T_A\circ T_B=T_{AB}$.
\end{ex}

\begin{exerc}
	Mostre, sem utilizar exemplos concretos, que se $f$ e $g$ são lineares, então $f\circ g$ e $g\circ f$ também são (dica: use o fato de que $f$ e $g$ preservam somas e produtos por números).
\end{exerc}

\subsection{Núcleo e imagem}

Agora vamos introduzir dois conceitos que vão nos ajudar a entender ainda melhor o espaço de vetores e transformações lineares.

\begin{df}
	Dada uma função linear $f:\R^2\to \R^2$ definimos o \textbf{núcleo de $f$} como sendo o conjunto $\Ker f$ dado por
	\[\Ker f:=\{v\in \R^2\mid f(v)=(0,0)\}.\]
\end{df}

\begin{rmk}
	O símbolo $\Ker$ vem da palavra inglesa \emph{kernel} que significa ``a parte macia de um grão'' ou ``a parte central''.
\end{rmk}

\begin{ex}
	Considere função $f:\R^2\to\R^2$ que leva $(x,y)$ em $(x,0)$, ou seja, $f(x,y)=(x,0)$. Claramente, $f$ é linear (verifique!) e é dada pela matriz $A=\begin{pmatrix}
	1&0\\0&0
	\end{pmatrix}$ (verifique!!).
	
	Quem é o núcleo de $f$? São todos os pontos $(x,y)\in \R^2$ tais que $f(x,y)=(0,0)$. Mas $f(x,y)=(x,0)$. Então $(x,0)=f(x,y)=(0,0)$ se, e somente se, $x=0$ -  ou seja,
	\[\Ker f=\{(x,y)\in \R^2\mid x=0\}.\]
	
	Será que isso nos diz alguma coisa sobre a matriz $A$? Bom, resolvendo o sistema $AX=0$ temos:
	\[\begin{pmatrix}
	1&0\\0&0
	\end{pmatrix}\begin{pmatrix}
	x\\y
	\end{pmatrix}=\begin{pmatrix}
	0\\0
	\end{pmatrix}\]ou seja, $x=0$ e $0y=0$. Isso nos diz que
	\[S_0:=\{(x,y)\in\R^2\mid x=0\}.\]
	
	Mas isso é a mesma coisa que $\Ker f$!
	
	Em outras palavras, o núcleo de uma função linear \textbf{nada mais é do que o conjunto solução do sistema homogêneo associado àquela função}.
\end{ex}

\begin{prop}
	Para qualquer função linear $f:\R^2\to\R^2$, $\Ker f\neq \varnothing$.
\end{prop}
\begin{proof}
	Como $f$ é linear, existe matriz $A$ tal que $f=T_A$. Mas, pelo exemplo acima, vimos que $\Ker f= S_0$, em que $S_0$ é o conjunto de soluções de $AX=0$. Contudo, já vimos que $(0,0)\in S_0$. Segue que $(0,0)\in \Ker f$ e, portanto, $\Ker f\neq\varnothing$.
	
	
	Alternativamente, podemos calcular explicitamente:
	
	\[f(0,0)=f(1,0)+f(-1,0)=f(1,0)-f(1,0)=(0,0)\]e chegar à mesma conclusão.
\end{proof}

Agora vamos usar o núcleo para inferir alguns resultados importantes da álgebra vetorial:

\begin{prop}
	Seja $f:\R^2\to\R^2$ linear. Então $f$ é injetiva se, e somente se, $\Ker f=\{(0,0)\}$.
\end{prop}

\begin{proof}
	Se $f$ é injetiva, então $f(v)=f(u)$ implica $v=u$. Escolha, então, qualquer $v\in \Ker f$ - ou seja, $f(v)=(0,0)$. Mas, pela proposição anterior, sabemos que $f(0,0)=(0,0)$. Agora, como $f$ é injetiva e $v$ e $(0,0)$ têm a mesma imagem, isso implica que $v=(0,0)$. Ora, nós mostramos que qualquer elemento $v$ no núcleo \textbf{tem} que ser $(0,0)$ - segue que o único elemento do núcleo é $(0,0)$.
	
	Por outro lado, suponha que $\Ker f=\{(0,0)\}$. Tome, então, $v,u\in\R^2$ tais que $f(v)=f(u)$. Se mostrarmos que $v=u$, teremos mostrado que $f$ é injetiva. Mas $f$ é linear, então dizer que $f(v)=f(u)$ é a mesma coisa que dizer que $f(v-u)=(0,0)$. Mas estamos supondo que $\Ker f=\{(0,0)\}$ - ou seja, se $f(w)=(0,0)$, então $w=(0,0)$. Como nós temos que $f(v-u)=(0,0)$, nossa hipótese de $\Ker f=\{(0,0)\}$ nos garante que $v-u=(0,0)$. Finalmente, isso é a mesma coisa que $v=u$. Logo, nós concluímos que $f$ é, de fato, injetiva, o que encerra a demonstração.
\end{proof}

\begin{ex}
	Vamos voltar a comparar núcleos e soluções do sistema homogêneo. O resultado que mostramos acima nos diz que uma função linear é injetiva se, e somente se, o núcleo é ``trivial'' - ou seja, o sistema homogêneo só possui a solução trivial $S_0=\{(0,0)\}$. Como podemos interpretar, do ponto de vista de matrizes, a injetividade de uma função linear?
	
	Pela proposição acima, uma função linear é injetiva se, e somente se, o único ponto que vai no zero é o zero. Em termos de matrizes, então, isso significa ``uma matriz $A$ é \textit{injetiva} se $AX=0$ implica $X=0$''. Em outras palavras, uma matriz é injetiva se o sistema homogêneo \textit{possui solução única} (a solução trivial).
	
	Mas já vimos acima que um sistema tem solução única se, e somente se, a forma escalonada da matriz $A$ não possui linhas de zeros.
	
	Juntando tudo isso, vemos que \textit{uma matriz corresponde a uma função linear injetiva se, e somente se, sua forma escalonada \textbf{não possui} linhas de zeros}.
	
	\tcblower
	
	Por exemplo, considere as matrizes 
	\[A=\begin{pmatrix}
	1&0\\0&1
	\end{pmatrix},\quad B=\begin{pmatrix}
	1&1\\
	-1&1
	\end{pmatrix},\quad C=\begin{pmatrix}
	2&3\\
	4&6
	\end{pmatrix}.\] $A$ já está escalonada, e não possui linhas de zeros, então certamente $T_A$ é injetiva.
	
	$B$ ainda não está escalonada:
	\[\begin{pmatrix}
	1&1\\-1&1
	\end{pmatrix}\rightsquigarrow\begin{pmatrix}
	1&1\\0&2
	\end{pmatrix}\rightsquigarrow\begin{pmatrix}
	1&1\\0&1
	\end{pmatrix}\rightsquigarrow\begin{pmatrix}
	1&0\\0&1
	\end{pmatrix}.\] Então $B$ escalonada é $A$, que já vimos que não possui linhas de zeros. Segue que $T_B$ é injetiva.
	
	$C$ também não está escalonada ainda:
	\[\begin{pmatrix}
	2&3\\4&6
	\end{pmatrix}\rightsquigarrow\begin{pmatrix}
	1&3/2\\4&6
	\end{pmatrix}\rightsquigarrow\begin{pmatrix}
	1&3/2\\0&0
	\end{pmatrix}.\] Então $C$ escalonada tem uma linha de zeros, ou seja, $T_C$ \textbf{não} é injetiva.
\end{ex}

A discussão e os exemplos acima sugerem que toda função linear injetiva possui inverso. Isso pode soar estranho a princípio: Por exemplo, esquecendo o adjetivo ``linear'', sabemos que uma função $f$ entre dois conjuntos quaisquer possui inversa se, e somente se, $f$ é injetiva e sobrejetiva. Dito de outra maneira, em geral \textit{não basta uma função ser injetiva para que ela seja inversível}.

Essa é uma das grandes vantagens de funções lineares: Com o acréscimo desse adjetivo ``linear'', podemos mostrar o seguinte resultado:

\begin{theorem}
	Seja $f:\R^2\to \R^2$ uma função linear. Então $f$ é inversível se, e somente se, $f$ é injetiva, o que acontece se, e somente se, $f$ é sobrejetiva.
\end{theorem}

Em outras palavras, no mundo dos vetores e funções lineares, \textit{ser injetivo, sobrejetivo e inversível é \textbf{a mesma coisa}}.

Vamos agora caminhar em direção a demonstra esse resultado. Para isso vamos precisar de alguns conceitos.

\begin{df}
	Seja $S\subset \R^2$ um subconjunto de $\R^2$ tal que para quaisquer $v,u\in S$ e qualquer $\lambda\in\R$ temos que $v+\lambda u\in S$. Então diremos que $S$ é um \textbf{subespaço de $\R^2$}.
\end{df}

\begin{rmk}
	Note que, por definição, se $v\in S$ e $S$ é subespaço de $\R^2$, então $\lambda v$ também está em $S$, para qualquer $\lambda\in \R$. Disso segue que se $S\neq \varnothing$, então $S$ tem infinitos elementos.
\end{rmk}

\begin{exerc}
	Mostre que $\{(0,0)\}$, $\{(x,y)\in \R^2\mid y=\lambda x \mbox{ para algum }\lambda\in \R\}$ e $\R^2$ são subespaços de $\R^2$.
\end{exerc}

Com isso, podemos finalmente ter um bom resultado:

\begin{prop}
	Para qualquer função linear $f:\R^2\to\R^2$, temos que $\Ker f$ é um subespaço de $\R^2$.
\end{prop}

\begin{proof}
	Tome $v,u\in \Ker f$ e $\lambda\in \R$. Vamos mostrar que $f(v+\lambda u)=(0,0)$ e, portanto, $v+\lambda u\in \Ker f$. Calculando:
	\[f(v+\lambda u)=f(v)+f(\lambda u)=f(v)+\lambda f(u),\]já que $f$ é linear. Agora, como $v,u\in \Ker f$, temos que $f(v)=f(u)=(0,0)$, logo
	\[f(v+\lambda u)=f(v)+\lambda f(u)=(0,0)+\lambda (0,0)=(0,0)+(0,0)=(0,0),\]ou seja, $v+\lambda u\in \Ker f$. 
	
	Segue que $\Ker f$ é subespaço de $\R^2$, como queríamos mostrar.
\end{proof}
\begin{cor}
	Seja $f:\R^2\to\R^2$ linear. Então $\Ker f$ ou tem um único ponto ($(0,0)$) ou tem infinitos pontos. 
\end{cor}

\begin{rmk}
	O resultado acima é uma justificativa para a afirmação de que um sistema linear ou não tem solução, ou tem uma solução ou tem infinitas soluções.
\end{rmk}

\begin{exerc}
	Prove a observação acima - ou seja, tome qualquer sistema linear $AX=B$ com $A\in M_2(\R)$ e mostre que o conjunto de soluções ou é vazio, ou tem um único ponto, ou tem infinitos pontos.
\end{exerc}