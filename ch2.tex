\chapter{Real Linear Algebra}
\section{Introduction}
\subsection{First notions and definitions}

To start working with vector spaces we first need to understand that the perspective is going to change a bit from the previous chapter. We're leaving the domain of \textbf{set theory} and jumping right in the domain of \textbf{algebra}.

\textit{Algebra }is the domain of mathematics that deals with operations and their properties.

\begin{df}
	Given any set $X$, a \textbf{(binary) operation} on $X$ is a function $f:X\times X \to X$.
\end{df}

\begin{ex}
	Let $\N$ be the set of natural numbers, as before. We have a few operations here:
	\[f,g,h:\N\times\N \to \N\]
	\[(n,m)\mapsto f(n,m):=n+m\]
	\[(n,m)\mapsto g(n,m):=nm\]
	\[(n,m)\mapsto h(n,m):=n^m\]and some of these operations have some properties that the others don't.
	
	For instance, all three functions satisfy the following property:
	
	\begin{itemize}
		\item Let $\phi$ be an operation on $X$. There is some $n_e\in X$ such that $\phi(n,n_e)=n$ for all $n\in X$.
	\end{itemize}

	In the case of $f$, if we choose $n_e:=0$, we see that $f(n,0)=n+0=n$, no matter which $n\in \N$ we chose, so $f$ satisfies the property above.
	
	In the case of $g$, if we choose $n_e:=1$, we see that $g(n,1)=n\cdot1=n$, no matter which $n\in\N$ we chose, so $g$ satisfies the property above.
	
	Finally, in the case of $h$, if we choose $n_e:=1$, we see that $h(n,1)=n^1=n$, no matter which $n\in\N$ we chose, so $h$ satisfies the property above.
	
	\bigskip
	Next up is the property:
	
	\begin{itemize}
		\item Let $\phi$ be an operation on $X$. There is some $n_e\in X$ such that $\phi(n_e,n)=n$ for all $n\in X$.
	\end{itemize}

	What can we say about $f,g,h$ in this case? Well, it's easy to see that for $f$ and $g$ it still holds true - and it does so for the same value of $n_e$ as before.
	
	However, for $h$ it fails. For instance, is there some number $x\in\N$ such that $h(x,2)=2$? Well, by definition of $h$ we would need to have $x^2=2$ and so $x=\sqrt{2}$ which is not in $\N$ - this tells us that there's no such $x\in\N$. It follows that this property fails for $h$.
	
	\bigskip
	Summing up all of these together, we get the following property:
	\begin{itemize}
		\item (Identity element) Let $\phi$ be an operation on $X$. There is some $n_e\in X$ such that $\phi(n,n_e)=n=\phi(n_e,n)$ for all $n\in X$.
	\end{itemize}
	And we see that $f$ and $g$ have what's called an \textit{identity element} - it's an element $n_e$ such that if you fix it in any input of your operation, then your operation is just the identity function.
	
	\bigskip
	Consider now the following property:
	\begin{itemize}
		\item (Associativity) Let $\phi$ be an operation on $X$. Then, for all $n,m,l\in X$ we have that $\phi(\phi(n,m),l)=\phi(n,\phi(m,l))$.
	\end{itemize}

	In the case of $f$ we can check
	\[f(f(n,m),l)=f(n+m,l)=(n+m)+l=n+(m+l)=f(n,m+l)=f(n,f(m,l))\]and see that $f$ is associative.
	
	In the case of $g$ we can check
	\[g(g(n,m),l)=g(nm,l)=(nm)l=n(ml)=g(n,ml)=g(n,g(m,l))\]and see that $g$ is associative.
	
	However, for $h$, once again, this property fails: For instance, let us compare $h(h(2,2),3)$ and $h(2,h(2,3))$:
	\[h(h(2,2),3)=h(2^2,3)=(2^2)^3=4^3=64\]
	\[h(2,h(2,3))=h(2,2^3)=2^{(2^3)}=2^8=256\]so they are clearly different, and $h$ is not associative.
	
	\bigskip
	One more:
	\begin{itemize}
		\item (Commutativity) Let $\phi$ be an operation on $X$. Then, for all $n,m\in X$ we have that $\phi(n,m)=\phi(m,n)$.
	\end{itemize}

	In the case of $f$ we can easily see that $f(n,m)=n+m=m+n=f(m,n)$.
	
	Similarly for $g$, we see that $g(n,m)=nm=mn=g(m,n)$.
	
	But, once again, $h(2,3)=8\neq 9=h(3,2)$, so $h$ is not commutative.
	
	\bigskip
	These are the most common operations in $\N$ and some of their properties. Now, let us show something that is \textbf{not} an operation:
	
	Consider the functions $$f',g':\N\times\N\to\N$$\[(n,m)\mapsto f'(n,m):=n-m\]
	\[(n,m)\mapsto g'(n,m):=n/m.\]
	
	Notice that I've just lied to you - these are \textbf{not} functions. To see that, take $f'$ and apply it on $(3,1)$. By definition of function, $f'(3,1)$ should lie on $\N$, the codomain of $f'$. But, by definition of $f'$, we see that $f'(3,1)=3-1=-2$, which is \textbf{not} in $\N$.
	
	Similarly, $g'$ isn't a function for the same reason: It should take, for instance, $(1,2)$ to a natural number - but it doesn't. It takes $(1,2)$ to $g'(1,2)=1/2$ which, once more, is not a natural number.
	
	However, for \textit{some} specific values of the input, $f'$ and $g'$ really have outputs in $\N$. For that reason, they are called \textbf{partial operations} and, sadly, won't be studied in this text, since we're mostly concerned with proper operations.
	
	If, however, you'd like to learn more about partial operations, you should click \href{https://ncatlab.org/nlab/show/groupoid}{here} or Google for ``groupoid'' - which is precisely the mathematical notion of a set with an associative partial operation.
\end{ex}

\begin{df}
	Given an operation $\phi:X\times X\to X$ we will say that
	\begin{itemize}
		\item (Identity element) $\phi$ admits an \textbf{identity element} if there is some $e\in X$ such that $\phi(x,e)=x=\phi(e,x)$ for all $x\in X$. In this case, $e$ is called an \textbf{identity element};
		\item (Associativity) $\phi$ is \textbf{associative} if $\phi(x,\phi(y,z))=\phi(\phi(x,y),z)$ for all $x,y,z\in X$;
		\item (Commutative) $\phi$ is \textbf{commutative} if $\phi(x,y)=\phi(y,x)$ for all $x,y\in X$;
		\item (Inverse element) $\phi$ admits \textbf{inverse elements} if for all $x\in X$ there is some $y\in X$ such that $\phi(x,y)=e=\phi(y,x)$ for some identity element $e\in X$.
	\end{itemize}
\end{df}

\begin{df}
	Let $X$ be a set with two operations, $f,g:X\times X\to X$. We say that \textbf{$f$ distributes over $g$ on the left} (resp. \textbf{on the right}) if $$f(x,g(y,z))=g(f(x,y),f(x,z))$$ (resp. $$f(g(x,y),z)=g(f(x,z),f(y,z)))$$ for all $x,y,z\in X$.
	
	If $f$ distributes over $g$ on both sides, we simply say that \textbf{$f$ distributes over $g$}.
\end{df}
\begin{ex}
	Following up on the previous example, we see that $g$ (the multiplication) distributes over $f$ (the addition):
	\[g(n,f(m,l))=g(n,m+l)=n(m+l)=nm+nl=f(nm,nl)=f(g(n,m),g(n,l))\]
	\[g(f(n,m),l)=g(n+m,l)=(n+m)l=nl+ml=f(nl,ml)=f(g(n,l),g(m,l))\]but $f$ doesn't distribute (on either side!) over $g$:
	\[1+(1\cdot 1)=1+1=2\neq 4=2\cdot 2=(1+1)\cdot(1+1)\]
	\[(1\cdot 1)+1=1+1=2\neq 4=2\cdot 2=(1+1)\cdot(1+1)\]
\end{ex}

All this talk now brings us to a very specific definition:

\begin{df}
	Let $X$ be a set with two operatios $A,M:X\times X\to X$. We will say that $(X,A,M)$ is a \textbf{field} if
	\begin{multicols}{3}
		\begin{enumerate}[(1)]
			\item $A$ is associative;
			\item $A$ is commutative;
			\item $A$ has an identity element;
			\item $A$ has inverses;
			\item $M$ is associative;
			\item $M$ is commutative;
			\item $M$ has an identity element;
			\item $M$ has inverses (excluding the additive identities);
			\item $M$ distributes over $A$.
		\end{enumerate}
	\end{multicols}
	

In this case, we call $A$ and $M$, respectively, the field's \textbf{addition} and \textbf{multiplication} operations, and denote them simply by $x+y:=A(x,y)$ and $xy:=M(x,y)$ for all $(x,y)\in X\times X$.
\end{df}

\begin{prop}
	The set $\R$ of real numbers with the usual addition and multiplication is a field.
\end{prop}
\begin{proof}
	This is immediate, since for every $x,y,z\in\R$ we have:
	\begin{multicols}{3}
		\begin{enumerate}[(1)]
			\item $x+(y+z)=(x+y)+z$;
			\item $x+y=y+x$;
			\item $x+0=0+x=x$;
			\item $x+(-x)=(-x)+x=0$;
			\item $x(yz)=(xy)z$;
			\item $xy=yx$;
			\item $x\cdot 1=1\cdot x=x$;
			\item $xx^{-1}=x^{-1}x=1$ if $x\neq 0$;
			\item $x(y+z)=xy+xz$ and $(x+y)z=xz+yz$.
		\end{enumerate}
	\end{multicols}	
\end{proof}

\begin{ex}
	Notice, however, that the sets $\N$ and $\Z$, of the naturals and integers, respectively, are \textbf{not} fields: $\N$ doesn't have either additive or multiplicative inverses (so it fails properties (4) and (8)), and $\N$ doesn't have multiplicative inverses (so it fails property (8)).
	
	On the other hand, it's easy to see that $\Q$, the set of rational numbers, is indeed a field. It is actually constructed to be, in some sense, ``the smallest field which extends $\Z$/$\N$''.
	
	Finally, the set $\C$ of complex numbers is also a field if you define the inverse of $z=x+iy$ to be $z^{-1}:=\dfrac{x-iy}{x^2+y^2}$. Indeed:
	
	\[zz^{-1}=(x+iy)\left(\frac{x-iy}{x^2+y^2}\right)=\frac{x^2+y^2}{x^2+y^2}=1\]so it is indeed an inverse for $z$.
\end{ex}

Let us show some properties of fields:

\begin{lemma}
	Let $(k,+,\cdot)$ be a field. Then the following hold:
	\begin{enumerate}[(a)]
		\item There's a unique additive identity;
		\item For each $x\in k$, there's a unique additive inverse;
		\item There's a unique multiplicative identity;
		\item For each $x\in k$, there's a unique multiplicative inverse;
		\item Let $0$ be an additive identity of $k$. Then $0x=0$ for all $x\in k$.
		\item Let $1$ be a multiplicative identity of $k$. Then $-x=(-1)x$, where $(-1)+1=0$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	\begin{enumerate}[(a)]
		\item Let $0$ and $0'$ be two additive identities of $k$. Then
		\[0=0+0'=0'\]where the leftmost equality holds since $0'$ is additive identity, and the rightmost equality holds since $0$ is additive identity, and so $0=0'$.
		
		\item Given $x\in k$, let $x'$ and $x''$ be two additive inverses to $x$. Then
		\[x'=x'+0=x'+(x+x'')=(x'+x)+x''=0+x''=x''\]and so $x'=x''$.
		
		\item Let $1$ and $1'$ be two multiplicative identities of $k$. Then
		\[1=1\cdot1'=1'\]where the leftmost equality holds since $1'$ is a multiplicative identity, and the rightmost equality holds since $1$ is a multiplicative identity, so $1=1'$.
		
		\item Given $x\in k$, let $x''$ and $x''$ be two multiplicative inverses to $x$. Then
		\[x'=x'\cdot1=x'(xx'')=(x'x)x''=1\cdot x''=x''\]and so $x'=x''$.
		
		\item Given $x\in k$, we have that
		\[0x=(0+0)x=0x+0x\]since $k$ is a field and $0$ is the additive identity. Let $y\in k$ be the additive inverse of $0x$.
		
		Then, since the above is true, we can see that $(0x)+y=(0x+0x)+y$ is also true. But the LHS is just 0, since $y$ is the additive inverse of $0x$, and the RHS is just $(0x+0x)+y=0x+(0x+y)=0x+0=0x$, so the above equation evaluates to $0=0x$.
		
		\item Given $x\in k$, we have that $0x=(1+(-1))x$ since $1+(-1)=0$. But now, by the distributive property of fields we see that $0x=(1+(-1))x=(1)x+(-1)x$.
		
		But $0x=0$ and $1x=x$, so this is just $0=x+(-1)x$. Since additive inverses are unique, we see that $(-1)x=-x$.
	\end{enumerate}
\end{proof}

This result basically tells us that every field is ``similar'' to $\R$, in some sense.

\begin{rmk}
	The reason why we require that the multiplication has inverses for all elements \textit{except for 0} is precisely because of item (e) above. Since $0x=0$ for all $x$, if we could have some $0^{-1}$, then $0=00^{-1}=1$ so we would have $0=1$.
	
	But since $1x=x$ for all $x$, this would imply that $x=1x=0x=0$, so \textbf{every element of the field would have to be 0 for it to be consistent}.
	
	In other words, the only set that satisfies all the properties of a field and also has a multiplicative inverse to 0 is the set $\{0\}$.
	
	In fact:
\end{rmk}

\begin{prop}
	The set $1=\{0\}$ with addition and multiplication being equal and given by $0+0=0\cdot 0=0$ is a field. Its multiplicative and additive identities are $0$, who is also the inverse of $0$.
\end{prop}
\begin{proof}
	There's literally nothing to prove.
\end{proof}

Finally, to end this section, let us give some examples of fields that aren't $1$, $\Q$, $\R$ or $\C$.

\begin{ex}
	Let $p\in \N$ be a prime number (that is, there are only two ways to write $p=nm$: $n=p, m=1$ and $n=1, m=p$). Consider the set $p\in\N$ - that is, $p=\{0,1,2,\cdots,p-1\}$. We will give a field structure to $p$ as follows:
	
	For any $x,y\in p$, define:
	\begin{itemize}
		\item $x+y$ is the remainder of the division of $x+y$ in $\N$ by $p$;
		\item $xy$ is the remainder of the division of $xy$ in $\N$ by $p$.
	\end{itemize}

	We claim that $p$ with those two operations is a field, which will be denoted by either $\Z_p$, $\Z/p\Z$ or $\mathds F_p$.
	
	For instance, let us do some computations with $p=3$.
	
	In this case, $p=\{0,1,2\}$, and so we have the following tables of operations:
	
	\begin{center}
		\begin{tabu}{|c|[2pt]c|c|c|}
			\hline+&0&1&2\\
			\tabucline[2pt]{-} 0&0&1&2\\
			\hline 1&1&2&0\\
			\hline 2&2&0&1\\
			\hline 
		\end{tabu} and \begin{tabu}{|c|[2pt]c|c|c|}
			\hline $\times$&0&1&2\\
			\tabucline[2pt]{-} 0&0&0&0\\
			\hline 1&0&1&2\\
			\hline 2&0&2&1\\
			\hline 
		\end{tabu}
	\end{center}
	
	It is, then, readily seen that $0$ and $1$ are, respectively, the additive and multiplicative identities of $\mathds{F}_3$.
	
	We can also see that $1+2=0$ so 1 and 2 are additive inverses to each other. Similarly, we see that $1\cdot 1=1=2\cdot 2$ so both 1 and 2 are multiplicative inverses to themselves.
	
	This shows that $\mathds{F}_3$ is a field.
	
	Building similar tables of operations we can prove that any $\mathds{F}_p$ is a field.
	
	Let us now show the necessity of $p$ being a prime.
	
	\bigskip
	Let $4=\{0,1,2,3\}$. Let's try building the same operations:
	
	\begin{center}
		\begin{tabu}{|c|[2pt]c|c|c|c|}
			\hline
			+&0&1&2&3\\\tabucline[2pt]{-}
			0&0&1&2&3\\\hline
			1&1&2&3&0\\\hline
			2&2&3&0&1\\\hline
			3&3&0&1&2\\\hline 
		\end{tabu} and \begin{tabu}{|c|[2pt]c|c|c|c|}
			\hline
			$\times$&0&1&2&3\\\tabucline[2pt]{-}
			0&0&0&0&0\\\hline
			1&0&1&2&3\\\hline
			2&0&2&0&2\\\hline
			3&0&3&2&1\\\hline
		\end{tabu}
	\end{center}but this shows that $2$ doesn't have any multiplicative inverses: $2\cdot 0=0$, $2\cdot 1=2$, $2\cdot 2=0$ and $2\cdot 3=2$.
	
	But by definition of a field, the only element that has no multiplicative inverse is 0. But clearly $2\neq 0$ (since $1+2\neq 1$), so $\Z/4\Z$ cannot be a field.
	
	This happens precisely because $4$ can be written as $4=nm$ in \textit{three} different ways: $4=4\cdot1=1\cdot 4=2\cdot 2$.
	
	Since this isn't supposed to be a course on field theory, we won't go into much detail on how to prove that $\Z/n\Z$ is a field if, and only if, $n$ is prime.
\end{ex}

\newpage
\subsection{Real vector spaces}

Let us start this section with the set that will be the focus of most, if not all, of this chapter: $\R^2$.

By definition, $\R^2=\R\times \R$ is the set of ordered pairs of real numbers.

\begin{df}
	We're going to define the \textbf{addition} $A:\R^2\times \R^2\to \R^2$ to be given by $A((x,y),(z,w)):=(x+z,y+w)$ for any $(x,y),(z,w)\in\R^2$.
\end{df}

\begin{prop}
	The addition $A$ we've just defined satisfies the following properties:
	\begin{enumerate}[(i.)]
		\item $A$ is associative;
		\item $A$ is commutative;
		\item $A$ admits an identity element;
		\item $A$ admits inverses.
	\end{enumerate}
\end{prop}
\begin{proof}
	Choose any three elements $(a,b),(c,d),(e,f)\in\R^2$. Then:
	\begin{enumerate}[(i.)]
		\item \begin{align*}
			A\left(A\left((a,b),(c,d)\right),(e,f)\right)&=A((a+c,b+d),(e,f))\\
			&=((a+c)+e,(b+d)+f)\\
			&=(a+(c+e),b+(d+f))\\
			&=A((a,b),(c+e,d+f))=A((a,b),A((c,d),(e,f))),
		\end{align*}so $A$ is associative;
		
		\item \begin{align*}
		A((a,b),(c,d))&=(a+c,b+d)=(c+a,d+b)=A((c,d),(a,b))
		\end{align*}so $A$ is commutative;
		
		\item $A((a,b),(0,0))=(a+0,b+0)=(a,b)=(0+a,0+b)=A((0,0),(a,b))$ so $A$ has identity $(0,0)$;
		
		\item $A((a,b),(-a,-b))=(a-a,b-b)=(0,0)=(-a+a,-b+b)=A((-a,-b),(a,b))$ so $A$ has inverses.
	\end{enumerate}
\end{proof}

\begin{rmk}
	From now on, we're gonna denote $A((a,b),(c,d))$ by $(a,b)+(c,d)$ for any $(a,b),(c,d)\in \R^2$ since, by the preceding proposition, it behaves well-enough like number addition.
\end{rmk}

And it seems there's not much else we can do with $\R^2$ for now.

To proceed with our studies, then, we're gonna need a new approach.

\begin{df}
	We'll denote $E_*$ the \textbf{pointed Euclidean plane}. That is, $E$ is the set of all points in the Euclidean plane, and $*$ is a distinguished point.
\end{df}

\begin{ex}
	For instance,
	
	\[\definecolor{ududff}{rgb}{0.30196078431372547,0.30196078431372547,1.}
	\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\clip(-0.5,-2.) rectangle (7.,6.);
	\begin{scriptsize}
	\draw [fill=ududff] (0.94,0.96) circle (2.5pt);
	\draw[color=ududff] (1.08,1.33) node {$A$};
	\draw [fill=ududff] (5.06,2.92) circle (2.5pt);
	\draw[color=ududff] (5.2,3.29) node {$B$};
	\end{scriptsize}
	\end{tikzpicture}\] we can think of the set $E_A$ (whose elements are all points in the plane, including $A$ and $B$, but distinguishing $A$) and the set $E_B$ (whose elements are all points in the plane, including $A$ and $B$, but distinguishing $B$).
\end{ex}

\begin{df}
	Given a pointed Euclidean plane $E_*$, we define a \textbf{vector in $E_*$} to be any directed segment starting in $*$.
\end{df}

\begin{ex}
	Continuing the above example,
	\[
	\definecolor{ududff}{rgb}{0.30196078431372547,0.30196078431372547,1.}
	\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\clip(-3.18,-2.52) rectangle (6.,4.75);
	\draw [->] (0.94,0.96) -- (2.2,3.56);
	\draw [->] (0.94,0.96) -- (-2.32,1.66);
	\draw [->] (0.94,0.96) -- (-0.06,-1.7);
	\draw [->] (0.94,0.96) -- (5.5,0.1);
	\draw [->] (0.94,0.96) -- (4.34,2.82);
	\draw [->] (5.06,2.92) -- (4.34,2.82);
	\draw [->] (5.06,2.92) -- (5.5,0.1);
	\draw [->] (5.06,2.92) -- (6,0);
	\begin{scriptsize}
	\draw [fill=ududff] (0.94,0.96) circle (2.5pt);
	\draw[color=ududff] (0.72,1.43) node {$A$};
%	\draw [fill=ududff] (4.34,2.82) circle (2.5pt);
%	\draw [fill=ududff] (5.5,0.1) circle (2.5pt);
%	\draw [fill=ududff] (-0.06,-1.7) circle (2.5pt);
%	\draw [fill=ududff] (-2.32,1.66) circle (2.5pt);
%	\draw [fill=ududff] (2.2,3.56) circle (2.5pt);	
	\draw [fill=ududff] (5.06,2.92) circle (2.5pt);
	\draw[color=black] (1.46,2.47) node {$s$};
	\draw[color=black] (-0.66,1.17) node {$v$};
	\draw[color=black] (0.62,-0.23) node {$w$};
	\draw[color=black] (3.28,0.79) node {$u$};
	\draw[color=black] (2.64,2.15) node {$t$};
	\draw[color=ududff] (5.2,3.29) node {$B$};
	\draw[color=black] (4.8,2.7) node {$x$};
	\draw[color=black] (5,1.5) node {$y$};	
	\draw[color=black] (5.8,1.5) node {$z$};
	\end{scriptsize}
	\end{tikzpicture}
	\]we see that $s,t,u,v,w$ are vectors in $E_A$, but not in $E_B$, whereas $x,y,z$ are vectors in $E_B$, but not in $E_A$.
\end{ex}

\begin{lemma}
	Let $V_A$ denote the set of all vectors in $E_A$. Then $E_A\iso V_A$.
\end{lemma}
\begin{proof}
	Consider the function $t:V_A\to E_A$ that takes any vector $v\in V_A$ to its endpoint $t(v)$, and takes the null vector to $A$.
	
	\begin{itemize}
		\item $t$ is injective:
		
		If $t(v)=t(u)$ for some $v,u\in V_A$, then $v$ and $u$ have the same endpoints. Since they also have the same starting points (by definition), they are equal - hence, $v=u$ and $t$ is injective.
		
		\item $t$ is surjective:
		
		Let $P\in E_A$ be a point. Consider the directed segment $\overrightarrow{AP}$. It is, by definition, a vector in $V_A$ whose endpoint is $P$, and, hence, $t(\overrightarrow{AP})=P$, and so $t$ is surjective.
	\end{itemize}

\begin{df}
	Given any vector $v\in V_A$, we define its \textbf{magnitude} or \textbf{size} or \textbf{norm} to be $\lVert v\rVert:=\lvert AP\rvert$, where $v=\overrightarrow{AP}$.
\end{df}

Since $t$ is both injective and surjective, it is a bijection. This proves the result.
\end{proof}

Let now $V^{r,s}_A$ be the following set: Take any two perpendicular lines $r$ and $s$ through $A$. Then, $V^{r,s}_A$ will be the set $(V_A\cap r)\times (V_A\cap s)$ - that is, the set of all pairs vectors of $E_A$ such that the first vector lies entirely in $r$ and the second vector lies entirely in $s$.

\begin{lemma}
	For any $E_A$, we have that $V_A\iso V^{r,s}_A$.
\end{lemma}
\begin{proof}
	Let $f:V_A\to V^{r,s}_A$ be the following function: For any vector $\overrightarrow{AP}$ in $V_A$, we can consider the parallel to $r$ through $P$, $r_P$ and the parallel to $s$ through $P$, $s_P$.
	
	Since $r\parallel r_P$, we have that $r\cap r_P=\varnothing$, and similarly we have that $s\cap s_P=\varnothing$.
	
	But since $r\nparallel s_P$ and they are both lines, we have that $r\cap s_P$ is a single point - let's call it $P_r$. Similarly, we see that $s\cap r_P$ is a single point - let's call it $P_s$.
	
	But now, $P_r\in r$, by definition. So $\overrightarrow{AP_r}$ is a vector which lies entirely in $r$. Similarly, $P_s\in s$ so $\overrightarrow{AP_s}$ is a vector which lies entirely in $s$.
	
	We then define $f(\overrightarrow{AP}):=(\overrightarrow{AP_r},\overrightarrow{AP_s})$.
	\[\definecolor{uuuuuu}{rgb}{0.26666666666666666,0.26666666666666666,0.26666666666666666}
	\definecolor{ududff}{rgb}{0.30196078431372547,0.30196078431372547,1.}
	\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\clip(-0.86,0.62) rectangle (8.56,7.02);
	\draw [->] (0.5,3.04) -- (7.5,4.08);
	\draw [->] (0.5,3.04) -- (1.0909987984666145,5.574475616501058);
	\draw [->] (0.5,3.04) -- (6.909001201533385,1.5455243834989414);
	\draw [domain=-0.86:8.56] plot(\x,{(--28.1568-2.08*\x)/8.92});
	\draw [domain=-0.86:8.56] plot(\x,{(--1.8632--8.92*\x)/2.08});
	\draw [dotted,domain=-0.86:8.56] plot(\x,{(-58.4136--8.92*\x)/2.08});
	\draw [dotted,domain=-0.86:8.56] plot(\x,{(-51.9936--2.08*\x)/-8.92});
	\begin{scriptsize}
	\draw [fill=ududff] (0.5,3.04) circle (2.5pt);
	\draw[color=ududff] (0.76,2.71) node {$A$};
	\draw[color=black] (-5.62,4.33) node {$r$};
	\draw[color=black] (2.16,9.29) node {$s$};
	\draw [fill=ududff] (7.5,4.08) circle (2.5pt);
	\draw[color=ududff] (7.76,4.37) node {$P$};
	\draw [fill=uuuuuu] (1.0909987984666145,5.574475616501058) circle (2.0pt);
	\draw[color=uuuuuu] (1.39,5.92) node {$P_s$};
	\draw [fill=uuuuuu] (6.909001201533385,1.5455243834989414) circle (2.0pt);
	\draw[color=uuuuuu] (7.29,1.94) node {$P_r$};
	\draw[color=uuuuuu] (3.29,2) node {$r$};
	\draw[color=uuuuuu] (0.5,4.5) node {$s$};
	\end{scriptsize}
	\end{tikzpicture}\]
	
	\begin{itemize}
		\item $f$ is injective:
		
		Let $v,u$ be vectors in $V_A$ such that $f(v)=f(u)$. This means that $v=\overrightarrow{AP}$ and $u=\overrightarrow{AQ}$ for some uniquely determined points $P,Q$ in $E_A$. Now, by definition, $f(v)=f(\overrightarrow{AP})=(\overrightarrow{AP_r},\overrightarrow{AP_s})$ and $f(u)=f(\overrightarrow{AQ})=(\overrightarrow{AQ_r},\overrightarrow{AQ_s})$.
		
		But $f(v)=f(u)$ implies $\overrightarrow{AP_r}=\overrightarrow{AQ_r}$ and $\overrightarrow{AP_s}=\overrightarrow{AQ_s}$, by definition of set product.
		
		But then this means that $P_r=Q_r$ and $P_s=Q_s$.
		
		This means that both $P$ and $Q$ belong to both of $r_P$ and $s_P$. But $r_P$ and $s_P$ are lines, so their intersection has, at most, one point. This means that $P=Q$, and so $f$ is injective.
		
		\item $f$ is surjective:
		
		Take any $(v,u)\in V^{r,s}_A$. Then, there are uniquely determined $P,Q\in E_A$ such that $v=\overrightarrow{AP}$ and $u=\overrightarrow{AQ}$.
		
		Now, consider the lines $r_Q$ and $s_P$ defined, respectively, to be the lines parallel to $r$ through $Q$, and parallel to $s$ through $P$.
		
		Since $s_P\parallel s\nparallel r\parallel r_Q$, we see that $s_P\nparallel r_Q$ and so $s_P\cap r_Q$ is a single point - T.
		
		It is, then, easy tos see that $f(\overrightarrow{AT})=(v,u)$, so $f$ is surjective.
	\end{itemize}

It follows then that $f$ is indeed a bijection, which ends the proof.
\end{proof}

Finally, we can prove the result we've all been waiting for:

\begin{theorem}
	Let $E_A$ be a pointed Euclidean plane. Then $V^{r,s}_A\iso \R^2$.
\end{theorem}
\begin{proof}
	Take any two points $R\in r$ and $P\in p$, respectively, both different from $A$.
	
	Now, given any $v\in r$ a vector lying entirely in $r$, we say that $v$ is \textbf{positive} if the endpoint of $v$ lies in the same side of the semiplane defined by $s$ as $R$, \textbf{zero} if $v=\overrightarrow{AA}$ the null vector, and \textbf{negative} otherwise.
	
	Similarly, given $u\in s$ a vector lying entirely in $s$, we say that $u$ is \textbf{positive} if the endpoint of $u$ lies in the same side of the samiplane defined by $r$ as $S$, \textbf{zero} if $u=\overrightarrow{AA}$ the null vector, and \textbf{negative} otherwise.
	
	This can be seen as a function $\mathrm{sgn}:V^{r,s}_A\to\{0,1,-1\}$.
	
	That said, we're gonna define a function $f:V^{r,s}_A\to \R^2$ by putting $$f(v,u):=(\mathrm{sgn}(v)\lVert v\rVert,\mathrm{sgn}(u)\lVert u\rVert).$$ We claim that $f$ is the bijection we're looking for.
	
	\begin{itemize}
		\item $f$ is injective:
		
		Let $(v,u),(v',u')\in V^{r,s}_A$ be two elements such that $f(v,u)=f(v',u')$. This means that $\mathrm{sgn}(v)\norm{v}=\mathrm{sgn}(v')\norm{v'}$ and $\mathrm{sgn}(u)\norm{u}=\mathrm{sgn}(u')\norm{u'}$. Since $\norm-$ is always a non-negative number, we see that $\mathrm{sgn}(v)\norm{v}=\mathrm{sgn}(v')\norm{v'}$ if, and only if, $\mathrm{sgn}(v)=\mathrm{sgn}(v')$, and similarly for $\mathrm{sgn}(u)=\mathrm{sgn}(u')$.
		
		Now this implies, together with the equations $\mathrm{sgn}(v)\norm{v}=\mathrm{sgn}(v')\norm{v'}$ and $\mathrm{sgn}(u)\norm{u}=\mathrm{sgn}(u')\norm{u'}$, that $\norm{v}=\norm{v'}$ and $\norm{u}=\norm{u'}$. But since the norm is entirely determined by the endpoint (since the starting point is fixed, being $A$), we see that $\norm{v}=\norm{v'}$ if, and only if, $v$ and $v'$ have the same endpoints. Similarly, we see that $u$ and $u'$ have the same endpoints.
		
		Finally, since $v$ and $v'$ have the same endpoints they must be equal, and the same goes for $u$ and $u'$.
		
		It follows that $(v,u)=(v',u')$ and so $f$ is indeed injective.
		
		\item $f$ is surjective:
		
		Take any $(x,y)\in \R^2$. Now draw two circles centered in $A$: one with radius $\abs{x}$ and one with radius $\abs{y}$. Call these circles $C_x$ and $C_y$, resp.
		
		Since $C_x$ is a circle and $r$ is a line which contains a point inside the circle, we know that $C_x\cap r$ is precisely two points - $R_1,R_2$. Similarly, we know that $C_y\cap s$ is precisely two points - $S_1,S_2$.
		
		Now, we take $\overrightarrow{x}$ to be the vector ending at either $R_1$ or $R_2$ such that $\mathrm{sgn}(\overrightarrow{x})=\mathrm{sgn}(x)$. Similarly, we define $\overrightarrow{y}$ to be the vector ending at either $S_1$ or $S_2$ such that $\mathrm{sgn}(\overrightarrow{y})=\mathrm{sgn}(y)$.
		
		Now, by construction, $(\overrightarrow{x},\overrightarrow{y})\in V^{r,s}_A$ is such that $\mathrm{sgn}(\overrightarrow{x})\norm{\overrightarrow{x}}=x$ and $\mathrm{sgn}(\overrightarrow{y})\norm{\overrightarrow{y}}=y$, so $f(\overrightarrow{x},\overrightarrow{y})=(x,y)$ and we see that $f$ is surjective.
	\end{itemize}

Finally, we can conclude that $f$ is the bijection we were looking for. This ends the proof of the theorem.
\end{proof}
\begin{cor}
	By composition of isomorphisms we have:
	
	\[E_A\iso V_A\iso V^{r,s}_A\iso\R^2,\]so the elements of $\R^2$ can be thought of as vectors in the pointed Euclidean plane $E_A$.
\end{cor}

\begin{lemma}
	In the above bijection $f:V^{r,s}_A\to\R^2$, the image of $r$ is the set
	\[\R\times\{0\}:=\{(x,y)\in \R^2\mid y=0\}\]and the image of $s$ is the set
	\[\{0\}\times \R:=\{(x,y)\in\R^2\mid x=0\}.\]
\end{lemma}
\begin{proof}
	Take $(v,\overrightarrow{AA})\in V^{r,s}_A$ any vector lying entirely on $r$. Then, by definition,
	\[f(v,\overrightarrow{AA})=(\mathrm{sgn}(v)\norm{v},\mathrm{sgn}(\overrightarrow{AA})\norm{\overrightarrow{AA}}),\]but both $\mathrm{sgn}(\overrightarrow{AA})$ and $\norm{\overrightarrow{AA}}$ equal 0. So $f(v,\overrightarrow{AA})=(\mathrm{sgn}(v)\norm{v},0)$.
	
	This shows that $f(r)\subseteq \R\times\{0\}$.
	
	Conversely, take any $(x,0)\in \R\times\{0\}$. It is clearly the image of some vector pair $(\overrightarrow{x},\overrightarrow{AA})$, and so $\R\times\{0\}\subseteq f(r)$.
	
	We can argue analogously and show that $f(s)=\{0\}\times\R$.
	
	This ends the proof.
\end{proof}

\begin{df}
	We will denote the sets $\R\times\{0\}$ and $\{0\}\times \R$ the \textbf{$X$-axis} and the \textbf{$Y$-axis}, respectively.
\end{df}

\begin{rmk}
	Notice that, as sets, both the $X$- and the $Y$-axis are in bijection with $\R$, and with a line (the $X$-axis is in bijection with $r$ and the $Y$-axis is in bijection with $s$).
	
	Therefore, $\R$ is in bijection with a line. So it makes sense to think of the set of real numbers as a \textit{line}, and call it the \textbf{real line}.
\end{rmk}

Finally, to end this section, one last result:

\begin{lemma}
	Take $t\in E_A$ any line through $A$. Then there is some point $(x_t,y_t)\in \R^2$ such that $f(t)=\{(x,y)\in\R^2\mid x=\lambda x_t \mbox{ and }y=\lambda y_t,\mbox{ for some }\lambda\in\R\}$.
\end{lemma}
\begin{proof}
	Let $\R(x_t,y_t)$ denote the set $\{(x,y)\in\R^2\mid x=\lambda x_t \mbox{ and }y=\lambda y_t,\mbox{ for some }\lambda\in\R\}$.
	
	Draw $\mc C(A,1)$ the circle of radius $1$ centered at $A$. Since $t$ contains a point in the inside of the circle, $t\cap \mc C(A,1)=2$. Choose any of those two points and call it $P$.
	
	Now, let us define $(x_t,y_t):=f(\overrightarrow{AP_r},\overrightarrow{AP_s})$.
	
	Now take any point $T\in t$, and look at the vectors $\overrightarrow{AT_r}$ and $\overrightarrow{AT_s}$. Now, by using similar triangles we see that 
	\[\dfrac{\mathrm{sgn}(\overrightarrow{AT_r})\norm{\overrightarrow{AT_r}}}{x_t}=\dfrac{\mathrm{sgn}(\overrightarrow{AT_s})\norm{\overrightarrow{AT_s}}}{y_t}=\frac{\mathrm{sgn(\overrightarrow{AT})\norm{\overrightarrow{AT}}}}{\mathrm{sgn}(\overrightarrow{AP})\norm{\overrightarrow{AP}}}\]
	\[\definecolor{xdxdff}{rgb}{0.49019607843137253,0.49019607843137253,1.}
	\definecolor{ududff}{rgb}{0.30196078431372547,0.30196078431372547,1.}
	\definecolor{uuuuuu}{rgb}{0.26666666666666666,0.26666666666666666,0.26666666666666666}
	\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
	\begin{axis}[
	x=1.0cm,y=1.0cm,
	axis lines=middle,
	xmin=-1.2799999999999998,
	xmax=6.560000000000002,
	ymin=-1.3500000000000016,
	ymax=4.3500000000000005,
	yticklabels={},	
	xticklabels={},	
	xlabel=$r$,
	ylabel=$s$,]
	\clip(-1.28,-1.35) rectangle (6.56,4.35);
	\draw [domain=-1.28:6.56] plot(\x,{(-0.--1.67*\x)/3.04});
	\draw [dotted] (5.261710485848469,-1.35) -- (5.261710485848469,4.35);
	\draw [dotted] (3.04,-1.35) -- (3.04,4.35);
	\draw [dotted,domain=-1.28:6.56] plot(\x,{(-1.67-0.*\x)/-1.});
	\draw [dotted,domain=-1.28:6.56] plot(\x,{(-2.890479115581231-0.*\x)/-1.});
	\draw [->] (0.,0.) -- (3.04,0.);
	\draw [->] (0.,0.) -- (5.261710485848469,0.);
	\draw [->] (0.,0.) -- (0.,1.67);
	\draw [->] (0.,0.) -- (0.,2.890479115581231);
	\draw [->] (0.,0.) -- (3.04,1.67);
	\draw [->] (0.,0.) -- (5.261710485848469,2.890479115581231);
	\begin{scriptsize}
	\draw [fill=uuuuuu] (0.,0.) circle (2.0pt);
	\draw[color=uuuuuu] (0.22,-0.28) node {$A$};
	\draw [fill=ududff] (3.04,1.67) circle (2.5pt);
	\draw[color=ududff] (3.24,1.48) node {$P$};
	\draw [fill=xdxdff] (5.261710485848469,2.890479115581231) circle (2.5pt);
	\draw[color=xdxdff] (5.54,2.66) node {$T$};
	\draw [fill=uuuuuu] (3.04,0.) circle (2.0pt);
	\draw[color=uuuuuu] (3.27,-0.4) node {$P_r$};
	\draw [fill=uuuuuu] (0.,1.67) circle (2.0pt);
	\draw[color=uuuuuu] (-0.35,1.9) node {$P_s$};
	\draw [fill=uuuuuu] (0.,2.890479115581231) circle (2.0pt);
	\draw[color=uuuuuu] (-0.33,3.3) node {$T_s$};
	\draw [fill=uuuuuu] (5.261710485848469,0.) circle (2.0pt);
	\draw[color=uuuuuu] (5.51,-0.4) node {$T_r$};
	\end{scriptsize}
	\end{axis}
	\end{tikzpicture}\]
	
	So we pick $\lambda_T$ to be any of those (since they're all equal).
	
	Clearly, then, by definition of $\lambda_T$, we have that $$f(\overrightarrow{AT_r},\overrightarrow{AT_s})=(\mathrm{sgn}(\overrightarrow{AT_r})\norm{AT_r},\mathrm{sgn}(\overrightarrow{AT_s})\norm{AT_s})=(\lambda_Tx_t,\lambda_Ty_t).$$
	
	Since this holds true for any $T\in t$, we have that $f(t)\subseteq \R(x_t,y_t)$.
	
	\bigskip
	Conversely, take some $(x_t,y_t)\in\R^2$ fixed.
	
	Now, let $P$ be the inverse image of $(x_t,y_t)$ under $f$ (it can be done uniquely since $f$ is bijective), and let $t$ be the line through $A$ that also passes through $P$ (it is also unique, since a line is uniquely determined by two distinct points).
	
	By the same reasoning as before, if we now take the inverse image of $(\lambda x_t,\lambda y_t)$ for any real $\lambda\in \R$ to be some $P^\lambda$, we see that the triangles $AP_rP_s$ and $AP^\lambda_rP^\lambda_s$ are similar, since 
	\[\frac{\overline{AP_r}}{\overline{AP^\lambda_r}}=\frac{\overline{AP_s}}{\overline{AP^\lambda_s}}=\frac{\overline{P_sP_r}}{\overline{P^\lambda_sP^\lambda_r}}=\lambda,\]so $P^\lambda$ lies in $t$.
	
	This shows that $\R(x_t,y_t)\subseteq f(t)$.
	
	Finally, we can conclude that $f(t)=\R(x_t,y_t)$, which ends the proof.
\end{proof}